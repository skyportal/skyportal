# Inspired by https://github.com/growth-astro/growth-too-marshal/blob/main/growth/too/gcn.py

import asyncio
import ast
from astropy.time import Time
from astropy.table import Table
import binascii
import healpy as hp
import io
import json
import os
import gcn
import ligo.skymap.bayestar as ligo_bayestar
import ligo.skymap.io
import ligo.skymap.postprocess
import lxml
import xmlschema
from urllib.parse import urlparse, urlsplit
import tempfile
from tornado.ioloop import IOLoop
import arrow
import astropy
import humanize
import requests
import sqlalchemy as sa
from sqlalchemy import String, func
from sqlalchemy.orm import joinedload
from sqlalchemy.orm import sessionmaker, scoped_session
from sqlalchemy.sql.expression import cast
from sqlalchemy.dialects.postgresql import JSONB
from sqlalchemy.orm.attributes import flag_modified
from marshmallow import Schema, validate
from marshmallow.fields import (
    Integer,
)
from marshmallow.exceptions import ValidationError
import numpy as np
import operator  # noqa: F401

from skyportal.models.photometry import Photometry

from .observation import get_observations, MAX_OBSERVATIONS
from .source import get_source, get_sources, serialize, MAX_SOURCES_PER_PAGE
from .galaxy import get_galaxies, get_galaxies_completeness, MAX_GALAXIES
import pandas as pd
from tabulate import tabulate
import datetime
from ...utils.UTCTZnaiveDateTime import UTCTZnaiveDateTime

from baselayer.app.access import auth_or_token, permissions
from baselayer.app.json_util import to_json
from baselayer.log import make_log
from baselayer.app.env import load_env
from baselayer.app.flow import Flow

from .gcn_gracedb import post_gracedb_data
from .source import post_source
from ..base import BaseHandler
from ...models import (
    DBSession,
    Allocation,
    CatalogQuery,
    DefaultGcnTag,
    DefaultObservationPlanRequest,
    EventObservationPlan,
    GcnEvent,
    GcnNotice,
    GcnProperty,
    GcnReport,
    GcnSummary,
    GcnTag,
    GcnTrigger,
    Instrument,
    InstrumentField,
    InstrumentFieldTile,
    Localization,
    LocalizationProperty,
    LocalizationTile,
    LocalizationTag,
    MMADetector,
    Obj,
    ObservationPlanRequest,
    User,
    Group,
    UserNotification,
    Source,
    SourcesConfirmedInGCN,
    SurveyEfficiencyForObservations,
)
from ...utils.gcn import (
    get_dateobs,
    get_properties,
    get_skymap_properties,
    get_skymap_metadata,
    get_json_tags,
    get_tags,
    get_notice_aliases,
    get_trigger,
    get_skymap,
    get_contour,
    from_url,
    from_bytes,
    from_cone,
    from_ellipse,
    from_polygon,
    has_skymap,
)
from .observation_plan import post_observation_plan
from ...utils.notifications import post_notification

from skyportal.models.gcn import SOURCE_RADIUS_THRESHOLD

log = make_log('api/gcn_event')

env, cfg = load_env()

Session = scoped_session(sessionmaker())

MAX_GCNEVENTS = 1000


def post_gcnevent_from_xml(
    payload, user_id, session, post_skymap=True, asynchronous=True, notify=True
):
    """Post GcnEvent to database from voevent xml.
    payload: str
        VOEvent readable string
    user_id : int
        SkyPortal ID of User posting the GcnEvent
    session: sqlalchemy.Session
        Database session for this transaction
    """

    user = session.query(User).get(user_id)

    schema = f'{os.path.dirname(__file__)}/../../utils/schema/VOEvent-v2.0.xsd'
    voevent_schema = xmlschema.XMLSchema(schema)
    if voevent_schema.is_valid(payload):
        # check if is string
        try:
            payload = payload.encode('ascii')
        except AttributeError:
            pass
        root = lxml.etree.fromstring(payload)
    else:
        raise ValueError("xml file is not valid VOEvent")

    gcn_notice = session.scalars(
        GcnNotice.select(user).where(GcnNotice.ivorn == root.attrib['ivorn'])
    ).first()
    if gcn_notice is not None:
        raise ValueError(f"GcnNotice with ivorn {root.attrib['ivorn']} already exists.")

    dateobs = get_dateobs(root)
    trigger_id = get_trigger(root)
    notice_type = gcn.get_notice_type(root)
    if notice_type not in list(gcn.NoticeType):
        notice_type = gcn.NoticeType.TEST_COORDS

    aliases = get_notice_aliases(
        root, notice_type
    )  # we try to get the aliases from the notice if possible

    if trigger_id is not None:
        event = session.scalars(
            GcnEvent.select(user).where(GcnEvent.trigger_id == trigger_id)
        ).first()
    else:
        event = session.scalars(
            GcnEvent.select(user).where(GcnEvent.dateobs == dateobs)
        ).first()

    if event is None:
        event = GcnEvent(
            dateobs=dateobs,
            sent_by_id=user_id,
            trigger_id=trigger_id,
            aliases=aliases,
        )
        session.add(event)
        session.commit()
        dateobs = event.dateobs
    else:
        dateobs = event.dateobs
        # we grab the dateobs from the event to overwrite the dateobs from the gcn notice
        # this is important because unfortunately the dateobs in a gcn notice is not always the same as the dateobs in the event
        # what matters is the trigger id if it exists, that allows us to find the actual dateobs of the event

        if not event.is_accessible_by(user, mode="update"):
            raise ValueError(
                "Insufficient permissions: GCN event can only be updated by original poster"
            )

    event_id = event.id

    gcn_notice = GcnNotice(
        content=payload,
        ivorn=root.attrib['ivorn'],
        notice_type=notice_type,
        stream=urlparse(root.attrib['ivorn']).path.lstrip('/'),
        date=root.find('./Who/Date').text,
        has_localization=has_skymap(root, notice_type),
        localization_ingested=False,
        dateobs=dateobs,
        sent_by_id=user_id,
        notice_format="voevent",
    )
    session.add(gcn_notice)
    session.commit()
    notice_id = gcn_notice.id

    properties_dict, tags_list = get_properties(root)
    properties = GcnProperty(dateobs=dateobs, sent_by_id=user_id, data=properties_dict)
    session.add(properties)
    session.commit()

    tags_text = [text for text in get_tags(root)] + tags_list
    tags = [
        GcnTag(
            dateobs=dateobs,
            text=text,
            sent_by_id=user_id,
        )
        for text in tags_text
    ]
    session.add_all(tags)
    session.commit()

    mma_detectors = session.scalars(
        MMADetector.select(user).where(MMADetector.nickname.in_(tags_text))
    ).all()
    if len(mma_detectors) > 0:
        event_to_update = session.scalars(
            GcnEvent.select(user).where(GcnEvent.dateobs == dateobs)
        ).first()
        event_to_update.mma_detectors = mma_detectors
        session.commit()

    gracedb_id = None
    aliases = event.aliases
    for alias in aliases:
        if "LVC" in alias:
            gracedb_id = alias.split("#")[-1]
            break

    if gracedb_id is not None:
        if asynchronous:
            try:
                loop = asyncio.get_event_loop()
            except Exception:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            IOLoop.current().run_in_executor(
                None,
                lambda: post_gracedb_data(event.dateobs, gracedb_id, user_id),
            )
        else:
            post_gracedb_data(event.dateobs, gracedb_id, user_id)

    found_skymap = False
    if post_skymap:
        try:
            post_skymap_from_notice(
                dateobs, notice_id, user_id, session, asynchronous, notify
            )
            found_skymap = True
        except Exception:
            found_skymap = False
            pass

    if not found_skymap and notify:
        # if there is no skymap, we still want to add the default tags that might not need localization tags
        gcn_tags = add_default_gcn_tags(user, session, dateobs=dateobs)
        if gcn_tags is not None and len(gcn_tags) > 0:
            session.add_all(gcn_tags)
        try:
            loop = asyncio.get_event_loop()
        except Exception:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

        request_body = {
            'target_class_name': 'GcnNotice',
            'target_id': notice_id,
        }

        IOLoop.current().run_in_executor(
            None,
            lambda: post_notification(request_body, timeout=30),
        )

    return dateobs, event_id, notice_id


def post_skymap_from_notice(
    dateobs, notice_id, user_id, session, asynchronous=True, notify=True
):
    """Post skymap to database from gcn notice."""
    user = session.query(User).get(user_id)

    gcn_notice = session.scalars(
        GcnNotice.select(user).where(GcnNotice.id == notice_id)
    ).first()

    if gcn_notice is None:
        raise ValueError(f"No GcnNotice with id {notice_id} found.")

    try:
        root = lxml.etree.fromstring(gcn_notice.content)
        notice_type = gcn.get_notice_type(root)
    except lxml.etree.XMLSyntaxError:
        root = json.loads(gcn_notice.content.decode('utf8'))
        notice_type = None

    skymap, url, properties, tags = None, None, None, None
    try:
        skymap, url, properties, tags = get_skymap(root, notice_type)
    except Exception as e:
        raise ValueError(f"Failed to get skymap from gcn notice {gcn_notice.id}: {e}")

    if skymap is None:
        raise Exception(f"No skymap found for event {dateobs} with notice {notice_id}")

    skymap["dateobs"] = dateobs
    skymap["sent_by_id"] = user_id

    localization_id = None
    localization = session.scalars(
        Localization.select(user).where(
            Localization.dateobs == skymap["dateobs"],
            Localization.localization_name == skymap["localization_name"],
        )
    ).first()
    if localization is None:
        localization = Localization(**skymap, notice_id=notice_id)
        session.add(localization)
        session.commit()
        localization_id = localization.id

        log(f"Generating tiles/properties/contours for localization {localization.id}")
        if asynchronous:
            try:
                loop = asyncio.get_event_loop()
            except Exception:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            IOLoop.current().run_in_executor(
                None,
                lambda: add_tiles_properties_contour_and_obsplan(
                    localization_id,
                    user_id,
                    url=url,
                    notify=notify,
                    properties=properties,
                    tags=tags,
                ),
            )
        else:
            add_tiles_properties_contour_and_obsplan(
                localization_id,
                user_id,
                session,
                url=url,
                notify=notify,
                properties=properties,
                tags=tags,
            )

        gcn_notice.localization_ingested = True
        session.add(gcn_notice)
        session.commit()
        try:
            ra, dec, error = (
                float(val) for val in skymap["localization_name"].split("_")
            )
            if error < SOURCE_RADIUS_THRESHOLD:
                source = {}
                if isinstance(root, dict):
                    name = root.get('name')
                    tags = get_json_tags(root)
                else:
                    name = root.find('./Why/Inference/Name')
                    tags = get_tags(root)
                    if name is not None:
                        name = name.text

                if name is not None:
                    source = {
                        'id': name.replace(' ', ''),
                        'ra': ra,
                        'dec': dec,
                    }
                elif any(
                    [True if 'GRB' in tag.text.upper() else False for tag in tags]
                ):
                    dateobs_txt = Time(dateobs).isot
                    source_name = f"GRB{dateobs_txt[2:4]}{dateobs_txt[5:7]}{dateobs_txt[8:10]}.{dateobs_txt[11:13]}{dateobs_txt[14:16]}{dateobs_txt[17:19]}"
                    source = {
                        'id': source_name,
                        'ra': ra,
                        'dec': dec,
                    }
                elif any([True if 'GW' in tag.text.upper() else False for tag in tags]):
                    dateobs_txt = Time(dateobs).isot
                    source_name = f"GW{dateobs_txt[2:4]}{dateobs_txt[5:7]}{dateobs_txt[8:10]}.{dateobs_txt[11:13]}{dateobs_txt[14:16]}{dateobs_txt[17:19]}"
                    source = {
                        'id': source_name,
                        'ra': ra,
                        'dec': dec,
                    }
                elif any(
                    [True if 'Einstein Probe' in tag.text else False for tag in tags]
                ):
                    dateobs_txt = Time(dateobs).isot
                    source_name = f"EP{dateobs_txt[2:4]}{dateobs_txt[5:7]}{dateobs_txt[8:10]}.{dateobs_txt[11:13]}{dateobs_txt[14:16]}{dateobs_txt[17:19]}"
                    source = {
                        'id': source_name,
                        'ra': ra,
                        'dec': dec,
                    }
                else:
                    source = {
                        'id': Time(dateobs).isot.replace(":", "-"),
                        'ra': ra,
                        'dec': dec,
                    }

                if source.get('id', None) is not None:
                    existing_source = session.scalars(
                        Source.select(user).where(Source.id == source['id'])
                    ).first()
                    if existing_source is None:
                        post_source(source, user_id, session)
        except Exception:
            pass

    else:
        localization_id = localization.id
        log(f"Localization {localization_id} already exists.")

    return localization_id


def post_gcnevent_from_json(
    payload, user_id, session, post_skymap=True, asynchronous=True, notify=True
):
    """Post GcnEvent to database from JSON.
    payload: dict
        JSON containing alert payload
    user_id : int
        SkyPortal ID of User posting the GcnEvent
    session: sqlalchemy.Session
        Database session for this transaction
    """

    # if payload is a string try to json.load it
    if isinstance(payload, str):
        try:
            payload = json.loads(payload)
        except Exception as e:
            raise ValueError(f"Could not load str payload: {e}")
    elif isinstance(payload, bytes):
        try:
            payload = json.loads(payload.decode('utf8'))
        except Exception as e:
            raise ValueError(f"Could not load str payload: {e}")
    elif not isinstance(payload, dict):
        raise ValueError(
            f"Unsupported JSON payload dtype, must be one of string, bytes, or dict, not {type(payload)}"
        )

    user = session.query(User).get(user_id)

    dateobs = Time(payload['trigger_time'], format="isot", precision=0)
    # FIXME: https://github.com/astropy/astropy/issues/7179
    dateobs = Time(dateobs.iso).datetime

    event = session.scalars(
        GcnEvent.select(user).where(GcnEvent.dateobs == dateobs)
    ).first()

    if event is None:
        event = GcnEvent(
            dateobs=dateobs,
            sent_by_id=user.id,
        )
        session.add(event)
    else:
        if not event.is_accessible_by(user, mode="update"):
            raise ValueError(
                "Insufficient permissions: GCN event can only be updated by original poster"
            )

    event_id = event.id

    tags = get_json_tags(payload)

    tags = [
        GcnTag(
            dateobs=event.dateobs,
            text=text,
            sent_by_id=user.id,
        )
        for text in tags
    ]

    detectors = []
    for tag in tags:
        session.add(tag)

        mma_detector = session.scalars(
            MMADetector.select(user).where(MMADetector.nickname == tag.text)
        ).first()
        if mma_detector is not None:
            detectors.append(mma_detector)
    event.detectors = detectors
    session.commit()

    date = dateobs
    if "alert_datetime" in payload:
        date = Time(payload['alert_datetime'], format="isot", precision=0)
        # FIXME: https://github.com/astropy/astropy/issues/7179
        date = Time(date.iso).datetime

    if "instrument" in payload:
        instrument = payload["instrument"]
    elif "type" in payload:
        instrument = payload["type"].replace(" ", "-")
    else:
        instrument = "Unknown"

    notice_type = payload.get('notice_type')
    gcn_notice = GcnNotice(
        content=json.dumps(payload).encode('utf-8'),
        ivorn=f'{instrument}-{date.strftime("%Y-%m-%dT%H:%M:%S")}',
        notice_type=notice_type,
        stream=instrument,
        date=date,
        has_localization=True,
        localization_ingested=False,
        dateobs=dateobs,
        sent_by_id=user_id,
        notice_format="json",
    )
    session.add(gcn_notice)
    session.commit()
    notice_id = gcn_notice.id

    found_skymap = False
    if post_skymap:
        try:
            post_skymap_from_notice(
                dateobs, notice_id, user_id, session, asynchronous, notify
            )
            found_skymap = True
        except Exception:
            found_skymap = False
            pass

    if not found_skymap and notify:
        # if there is no skymap, we still want to add the default tags that might not need localization tags
        gcn_tags = add_default_gcn_tags(user, session, dateobs=dateobs)
        if gcn_tags is not None and len(gcn_tags) > 0:
            session.add_all(gcn_tags)
        try:
            loop = asyncio.get_event_loop()
        except Exception:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

        request_body = {
            'target_class_name': 'GcnNotice',
            'target_id': notice_id,
        }

        IOLoop.current().run_in_executor(
            None,
            lambda: post_notification(request_body, timeout=30),
        )

    return dateobs, event_id, notice_id


def post_gcnevent_from_dictionary(payload, user_id, session, asynchronous=True):
    """Post GcnEvent to database from dictionary.
    payload: dict
        Dictionary containing dateobs and skymap
    user_id : int
        SkyPortal ID of User posting the GcnEvent
    session: sqlalchemy.Session
        Database session for this transaction
    """

    user = session.query(User).get(user_id)

    dateobs = payload['dateobs']

    event = session.scalars(
        GcnEvent.select(user).where(GcnEvent.dateobs == dateobs)
    ).first()

    if event is None:
        event = GcnEvent(dateobs=dateobs, sent_by_id=user.id)
        session.add(event)
    else:
        if not event.is_accessible_by(user, mode="update"):
            raise ValueError(
                "Insufficient permissions: GCN event can only be updated by original poster"
            )

    if "properties" in payload:
        properties = GcnProperty(
            dateobs=event.dateobs, sent_by_id=user.id, data=payload["properties"]
        )
        session.add(properties)

    tags = [
        GcnTag(
            dateobs=event.dateobs,
            text=text,
            sent_by_id=user.id,
        )
        for text in payload.get('tags', [])
    ]

    detectors = []
    for tag in tags:
        session.add(tag)

        mma_detector = session.scalars(
            MMADetector.select(user).where(MMADetector.nickname == tag.text)
        ).first()
        if mma_detector is not None:
            detectors.append(mma_detector)
    event.detectors = detectors
    session.commit()

    skymap = payload.get('skymap', None)
    if skymap is None:
        return event.id

    localization_properties, localization_tags = None, None
    if type(skymap) is dict:
        required_keys = {'localization_name', 'uniq', 'probdensity'}
        if not required_keys.issubset(set(skymap.keys())):
            required_cone_keys = {'ra', 'dec', 'error'}
            required_polygon_keys = {'localization_name', 'polygon'}
            required_ellipse_keys = {
                'localization_name',
                'ra',
                'dec',
                'amaj',
                'amin',
                'phi',
            }
            if required_cone_keys.issubset(set(skymap.keys())):
                skymap = from_cone(skymap['ra'], skymap['dec'], skymap['error'])
            elif required_ellipse_keys.issubset(set(skymap.keys())):
                skymap = from_ellipse(
                    skymap['localization_name'],
                    skymap['ra'],
                    skymap['dec'],
                    skymap['amaj'],
                    skymap['amin'],
                    skymap['phi'],
                )
            elif required_polygon_keys.issubset(set(skymap.keys())):
                if isinstance(skymap['polygon'], str):
                    polygon = ast.literal_eval(skymap['polygon'])
                else:
                    polygon = skymap['polygon']
                skymap = from_polygon(skymap['localization_name'], polygon)
            else:
                raise ValueError("ra, dec, and error must be in skymap to parse")
    else:
        try:
            skymap, localization_properties, localization_tags = from_bytes(skymap)
        except binascii.Error:
            skymap, localization_properties, localization_tags = from_url(skymap)

    skymap["dateobs"] = event.dateobs
    skymap["sent_by_id"] = user.id

    try:
        ra, dec, error = (float(val) for val in skymap["localization_name"].split("_"))
        if error < SOURCE_RADIUS_THRESHOLD:
            source = {
                'id': Time(event.dateobs).isot.replace(":", "-"),
                'ra': ra,
                'dec': dec,
            }
            post_source(source, user_id, session)
    except Exception:
        pass

    localization = session.scalars(
        Localization.select(user).where(
            Localization.dateobs == dateobs,
            Localization.localization_name == skymap["localization_name"],
        )
    ).first()
    if localization is None:
        localization = Localization(**skymap)
        session.add(localization)
        session.commit()
        localization_id = localization.id

        log(f"Generating tiles/properties/contours for localization {localization_id}")
        if asynchronous:
            try:
                loop = asyncio.get_event_loop()
            except Exception:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            IOLoop.current().run_in_executor(
                None,
                lambda: add_tiles_properties_contour_and_obsplan(
                    localization_id,
                    user_id,
                    properties=localization_properties,
                    tags=localization_tags,
                ),
            )
        else:
            add_tiles_properties_contour_and_obsplan(
                localization_id,
                user_id,
                session,
                properties=localization_properties,
                tags=localization_tags,
            )

    return event.id


class GcnEventAliasesHandler(BaseHandler):
    @auth_or_token
    def post(self, dateobs):
        """
        ---
        description: Post a GCN Event alias
        tags:
          - gcnevents
        parameters:
          - in: path
            name: dateobs
            required: true
            schema:
              type: string
            description: The dateobs of the event, as an arrow parseable string
        requestBody:
          content:
            application/json:
              schema:
                type: object
                properties:
                  alias:
                    type: string
                    description: Alias to add to the event
                required:
                  - alias
        responses:
          200:
            content:
              application/json:
                schema: Success
          400:
            content:
              application/json:
                schema: Error
        """
        data = self.get_json()
        alias = data.get('alias', None)

        if alias is None:
            return self.error("alias must be present in data")
        if type(alias) is not str:
            return self.error("alias must be a string")

        with self.Session() as session:
            try:
                event = session.scalars(
                    GcnEvent.select(
                        session.user_or_token,
                        mode="update",
                    ).where(GcnEvent.dateobs == dateobs)
                ).first()
                if event is None:
                    return self.error("GCN event not found", status=404)

                if event.aliases is None:
                    event.aliases = [alias]
                elif alias not in event.aliases:
                    event.aliases = list(set(event.aliases + [alias]))
                else:
                    return self.error(f'{alias} already in {dateobs} aliases.')
                session.commit()

                self.push(
                    action='skyportal/REFRESH_GCN_EVENT',
                    payload={"gcnEvent_dateobs": dateobs},
                )
            except Exception as e:
                return self.error(f'Cannot post alias: {str(e)}')

            return self.success()

    @auth_or_token
    def delete(self, dateobs):
        """
        ---
        description: Delete a GCN event alias
        tags:
          - gcnevents
        parameters:
          - in: path
            name: dateobs
            required: true
            schema:
              type: dateobs
        requestBody:
          content:
            application/json:
              schema:
                type: object
                properties:
                  alias:
                    type: string
                    description: Alias to remove from the event
                required:
                  - alias
        responses:
          200:
            content:
              application/json:
                schema: Success
          400:
            content:
              application/json:
                schema: Error
        """

        data = self.get_json()
        alias = data.get('alias')

        if alias is None:
            return self.error("alias must be present in data to remove")

        forbidden_substrings = ['LVC#', 'FERMI#']
        for forbidden_substring in forbidden_substrings:
            if forbidden_substring in alias:
                return self.error(
                    f"Cannot delete alias with substring {forbidden_substring}"
                )

        with self.Session() as session:
            try:
                event = session.scalars(
                    GcnEvent.select(
                        session.user_or_token,
                        mode="update",
                    ).where(GcnEvent.dateobs == dateobs)
                ).first()
                if event is None:
                    return self.error("GCN event not found", status=404)

                if alias in event.aliases:
                    aliases = event.aliases
                    aliases.remove(alias)
                    setattr(event, 'aliases', aliases)
                    flag_modified(event, 'aliases')
                else:
                    return self.error(f'{alias} not in {dateobs} aliases.')
                session.commit()

                self.push(
                    action='skyportal/REFRESH_GCN_EVENT',
                    payload={"gcnEvent_dateobs": dateobs},
                )
            except Exception as e:
                return self.error(f'Cannot remove alias: {str(e)}')

            return self.success()


class GcnEventTagsHandler(BaseHandler):
    @auth_or_token
    async def get(self, dateobs=None, tag=None):
        """
        ---
        description: Get all GCN Event tags
        tags:
          - photometry
        responses:
          200:
            content:
              application/json:
                schema: Success
          400:
            content:
              application/json:
                schema: Error
        """

        with self.Session() as session:
            tags = session.scalars(sa.select(GcnTag.text).distinct()).unique().all()
            return self.success(data=tags)

    @auth_or_token
    def post(self, dateobs=None, tag=None):
        """
        ---
        description: Post a GCN Event tag
        tags:
          - gcntags
        requestBody:
          content:
            application/json:
              schema: GcnEventTagPost
        responses:
          200:
            content:
              application/json:
                schema: Success
                properties:
                  data:
                    type: object
                    properties:
                      gcnevent_id:
                        type: integer
                        description: New GcnEvent Tag ID
          400:
            content:
              application/json:
                schema: Error
        """
        data = self.get_json()
        dateobs = data.get('dateobs', None)
        text = data.get('text', None)

        if dateobs is None:
            return self.error("dateobs must be present in data to add GcnTag")
        if text is None:
            return self.error("text must be present in data to add GcnTag")

        with self.Session() as session:
            try:
                tag = GcnTag(
                    dateobs=dateobs,
                    text=text,
                    sent_by_id=self.associated_user_object.id,
                )
                session.add(tag)
                session.commit()

                try:
                    loop = asyncio.get_event_loop()
                except Exception:
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)

                request_body = {
                    'target_class_name': 'GcnTag',
                    'target_id': tag.id,
                }

                IOLoop.current().run_in_executor(
                    None,
                    lambda: post_notification(request_body, timeout=30),
                )

                self.push(
                    action='skyportal/REFRESH_GCN_EVENT',
                    payload={"gcnEvent_dateobs": dateobs},
                )
            except Exception as e:
                return self.error(f'Cannot post tag: {str(e)}')

            return self.success(data={'gcntag_id': tag.id})

    @auth_or_token
    def delete(self, dateobs):
        """
        ---
        description: Delete a GCN event tag
        tags:
          - gcnevents
        parameters:
          - in: path
            name: dateobs
            required: true
            schema:
              type: dateobs
          - in: query
            name: tag
            required: true
            schema:
              type: tag
        responses:
          200:
            content:
              application/json:
                schema: Success
          400:
            content:
              application/json:
                schema: Error
        """

        data = self.get_json()
        tag = data.get('tag')
        if tag is None:
            return self.error("tag must be present in data to remove GcnTag")

        with self.Session() as session:
            tag = session.scalars(
                GcnTag.select(session.user_or_token, mode="delete").where(
                    GcnTag.dateobs == dateobs,
                    GcnTag.text == tag,
                )
            ).first()
            if tag is None:
                return self.error("GCN event tag not found", status=404)

            session.delete(tag)
            session.commit()

            self.push(
                action='skyportal/REFRESH_GCN_EVENT',
                payload={"gcnEvent_dateobs": dateobs},
            )

            return self.success()


class GcnEventPropertiesHandler(BaseHandler):
    @auth_or_token
    async def get(self):
        """
        ---
        description: Get all GCN Event properties
        tags:
          - photometry
        responses:
          200:
            content:
              application/json:
                schema: Success
          400:
            content:
              application/json:
                schema: Error
        """

        with self.Session() as session:
            properties = (
                session.scalars(
                    sa.select(sa.func.jsonb_object_keys(GcnProperty.data)).distinct()
                )
                .unique()
                .all()
            )
            return self.success(data=sorted(properties))


class GcnEventSurveyEfficiencyHandler(BaseHandler):
    @auth_or_token
    async def get(self, gcnevent_id):
        """
        ---
        description: Get survey efficiency analyses of the GcnEvent.
        tags:
          - gcnevents
        parameters:
          - in: path
            name: gcnevent_id
            required: true
            schema:
              type: string
        responses:
          200:
            content:
              application/json:
                schema: ArrayOfSurveyEfficiencyForObservationss
        """

        with self.Session() as session:
            event = session.scalars(
                GcnEvent.select(
                    session.user_or_token,
                    options=[joinedload(GcnEvent.survey_efficiency_analyses)],
                ).where(GcnEvent.id == gcnevent_id)
            ).first()
            if event is None:
                return self.error("GCN event not found", status=404)

            analysis_data = []
            for analysis in event.survey_efficiency_analyses:
                analysis_data.append(
                    {
                        **analysis.to_dict(),
                        'number_of_transients': analysis.number_of_transients,
                        'number_in_covered': analysis.number_in_covered,
                        'number_detected': analysis.number_detected,
                        'efficiency': analysis.efficiency,
                    }
                )

            return self.success(data=analysis_data)


class GcnEventObservationPlanRequestsHandler(BaseHandler):
    @auth_or_token
    async def get(self, gcnevent_id):
        """
        ---
        description: Get observation plan requests of the GcnEvent.
        tags:
          - gcnevents
        parameters:
          - in: path
            name: gcnevent_id
            required: true
            schema:
              type: string
        responses:
          200:
            content:
              application/json:
                schema: ArrayOfObservationPlanRequests
        """

        with self.Session() as session:
            event = session.scalars(
                GcnEvent.select(
                    session.user_or_token,
                    options=[
                        joinedload(GcnEvent.observationplan_requests)
                        .joinedload(ObservationPlanRequest.allocation)
                        .joinedload(Allocation.instrument),
                        joinedload(GcnEvent.observationplan_requests)
                        .joinedload(ObservationPlanRequest.allocation)
                        .joinedload(Allocation.group),
                        joinedload(GcnEvent.observationplan_requests).joinedload(
                            ObservationPlanRequest.requester
                        ),
                        joinedload(GcnEvent.observationplan_requests)
                        .joinedload(ObservationPlanRequest.observation_plans)
                        .joinedload(EventObservationPlan.statistics),
                    ],
                ).where(GcnEvent.id == gcnevent_id)
            ).first()

            # go through some pain to get probability and area included
            # as these are properties
            request_data = []
            if event is not None:
                for ii, req in enumerate(event.observationplan_requests):
                    dat = req.to_dict()
                    plan_data = []
                    for plan in dat["observation_plans"]:
                        plan_dict = plan.to_dict()
                        plan_dict['statistics'] = [
                            statistics.to_dict()
                            for statistics in plan_dict['statistics']
                        ]
                        plan_data.append(plan_dict)

                    dat["observation_plans"] = plan_data
                    request_data.append(dat)

            return self.success(data=request_data)


class GcnEventCatalogQueryHandler(BaseHandler):
    @auth_or_token
    async def get(self, gcnevent_id):
        """
        ---
        description: Get catalog queries of the GcnEvent.
        tags:
          - gcnevents
        parameters:
          - in: path
            name: gcnevent_id
            required: true
            schema:
              type: string
        responses:
          200:
            content:
              application/json:
                schema: ArrayOfCatalogQuerys
        """

        with self.Session() as session:
            queries = session.scalars(
                CatalogQuery.select(
                    session.user_or_token,
                ).where(CatalogQuery.payload['gcnevent_id'] == gcnevent_id)
            ).all()

            return self.success(data=queries)


class GcnEventHandler(BaseHandler):
    @auth_or_token
    def post(self):
        """
        ---
        description: Ingest GCN xml file
        tags:
          - gcnevents
          - gcntags
          - gcnnotices
          - localizations
        requestBody:
          content:
            application/json:
              schema: GcnHandlerPut
        responses:
          200:
            content:
              application/json:
                schema: Success
                properties:
                  data:
                    type: object
                    properties:
                      gcnevent_id:
                        type: integer
                        description: New GcnEvent ID
          400:
            content:
              application/json:
                schema: Error
        """
        data = self.get_json()
        # if an xml or json notice is not provided, then a dateobs must be specified
        if not any([format in data for format in ["xml", "json"]]):
            required_keys = {'dateobs'}
            if not required_keys.issubset(set(data.keys())):
                return self.error(
                    "Either xml, json or dateobs must be present in data to parse a GcnEvent"
                )

        event_id, dateobs, notice_id = None, None, None
        with self.Session() as session:
            try:
                if 'xml' in data:
                    dateobs, event_id, notice_id = post_gcnevent_from_xml(
                        data['xml'], self.associated_user_object.id, session
                    )
                elif 'json' in data:
                    dateobs, even_id, notice_id = post_gcnevent_from_json(
                        data['json'], self.associated_user_object.id, session
                    )
                else:
                    event_id = post_gcnevent_from_dictionary(
                        data, self.associated_user_object.id, session
                    )

                self.push(action='skyportal/REFRESH_GCN_EVENTS')
                self.push(action='skyportal/REFRESH_RECENT_GCNEVENTS')
            except Exception as e:
                return self.error(f'Cannot post event: {str(e)}')

            return self.success(
                data={
                    'gcnevent_id': event_id,
                    'dateobs': dateobs,
                    'notice_id': notice_id,
                }
            )

    @auth_or_token
    async def get(self, dateobs=None):
        f"""
        ---
        single:
          description: Retrieve a GCN event
          tags:
            - gcnevents
          parameters:
            - in: path
              name: dateobs
              required: false
              schema:
                type: string
        multiple:
          description: Retrieve multiple GCN events
          tags:
            - gcnevents
          parameters:
            - in: query
              name: startDate
              nullable: true
              schema:
                type: string
              description: |
                Arrow-parseable date string (e.g. 2020-01-01). If provided, filter by
                dateobs >= startDate
            - in: query
              name: endDate
              nullable: true
              schema:
                type: string
              description: |
                Arrow-parseable date string (e.g. 2020-01-01). If provided, filter by
                dateobs <= endDate
            - in: query
              name: gcnTagKeep
              nullable: true
              schema:
                type: string
              description: |
                Comma-separated string of `GcnTag`s. Returns events that match any of them.
            - in: query
              name: gcnTagRemove
              nullable: true
              schema:
                type: string
              description: |
                Comma-separated string of `GcnTag`s. Returns events that do not have any of these tags.
            - in: query
              name: localizationTagKeep
              nullable: true
              schema:
                type: string
              description: |
                Comma-separated string of `LocalizationTag`s. Returns events that match any of them.
            - in: query
              name: localizationTagRemove
              nullable: true
              schema:
                type: string
              description: |
                Comma-separated string of `LocalizationTag`s. Returns events that do not have any of these tags.
            - in: query
              name: gcnPropertiesFilter
              nullable: true
              schema:
                type: array
                items:
                  type: string
              explode: false
              style: simple
              description: |
                Comma-separated string of "property: value: operator" single(s) or triplet(s) to filter for events matching
                that/those property(ies), i.e. "BNS" or "BNS: 0.5: lt"
            - in: query
              name: localizationPropertiesFilter
              nullable: true
              schema:
                type: array
                items:
                  type: string
              explode: false
              style: simple
              description: |
                Comma-separated string of "property: value: operator" single(s) or triplet(s) to filter for event localizations matching
                that/those property(ies), i.e. "area_90" or "area_90: 500: lt"
            - in: query
              name: numPerPage
              nullable: true
              schema:
                type: integer
              description: |
                Number of GCN events to return per paginated request.
                Defaults to 10. Can be no larger than {MAX_GCNEVENTS}.
            - in: query
              name: pageNumber
              nullable: true
              schema:
                type: integer
              description: Page number for paginated query results. Defaults to 1.
        responses:
          200:
            content:
              application/json:
                schema: GcnEventHandlerGet
          400:
            content:
              application/json:
                schema: Error
        """

        partialdateobs = self.get_query_argument("partialdateobs", None)

        if dateobs is not None and partialdateobs is not None:
            return self.error(
                "Cannot specify both dateobs and partialdateobs query parameters"
            )

        page_number = self.get_query_argument("pageNumber", 1)
        try:
            page_number = int(page_number)
        except ValueError as e:
            return self.error(f'pageNumber fails: {e}')

        n_per_page = self.get_query_argument("numPerPage", 10)
        try:
            n_per_page = int(n_per_page)
        except ValueError as e:
            return self.error(f'numPerPage fails: {e}')

        if n_per_page > MAX_GCNEVENTS:
            return self.error(f'numPerPage should be no larger than {MAX_GCNEVENTS}.')

        sort_by = self.get_query_argument("sortBy", None)
        sort_order = self.get_query_argument("sortOrder", "asc")

        start_date = self.get_query_argument('startDate', None)
        end_date = self.get_query_argument('endDate', None)
        gcn_tag_keep = self.get_query_argument('gcnTagKeep', None)
        gcn_tag_remove = self.get_query_argument('gcnTagRemove', None)
        localization_tag_keep = self.get_query_argument('localizationTagKeep', None)
        localization_tag_remove = self.get_query_argument('localizationTagRemove', None)
        gcn_properties_filter = self.get_query_argument("gcnPropertiesFilter", None)

        if gcn_tag_keep is not None:
            if isinstance(gcn_tag_keep, str):
                gcn_tag_keep = [c.strip() for c in gcn_tag_keep.split(",")]
            else:
                raise ValueError(
                    "Invalid gcnTagKeep value -- must provide at least one string value"
                )

        if gcn_tag_remove is not None:
            if isinstance(gcn_tag_remove, str):
                gcn_tag_remove = [c.strip() for c in gcn_tag_remove.split(",")]
            else:
                raise ValueError(
                    "Invalid gcnTagRemove value -- must provide at least one string value"
                )

        if localization_tag_keep is not None:
            if isinstance(localization_tag_keep, str):
                localization_tag_keep = [
                    c.strip() for c in localization_tag_keep.split(",")
                ]
            else:
                raise ValueError(
                    "Invalid localizationTagKeep value -- must provide at least one string value"
                )

        if localization_tag_remove is not None:
            if isinstance(localization_tag_remove, str):
                localization_tag_remove = [
                    c.strip() for c in localization_tag_remove.split(",")
                ]
            else:
                raise ValueError(
                    "Invalid localizationTagRemove value -- must provide at least one string value"
                )

        if gcn_properties_filter is not None:
            if isinstance(gcn_properties_filter, str):
                gcn_properties_filter = [
                    c.strip() for c in gcn_properties_filter.split(",")
                ]
            else:
                raise ValueError(
                    "Invalid gcnPropertiesFilter value -- must provide at least one string value"
                )

        localization_properties_filter = self.get_query_argument(
            "localizationPropertiesFilter", None
        )

        if localization_properties_filter is not None:
            if isinstance(localization_properties_filter, str):
                localization_properties_filter = [
                    c.strip() for c in localization_properties_filter.split(",")
                ]
            else:
                raise ValueError(
                    "Invalid localizationPropertiesFilter value -- must provide at least one string value"
                )

        if dateobs is not None:
            with self.Session() as session:
                event = session.scalars(
                    GcnEvent.select(
                        session.user_or_token,
                        options=[
                            joinedload(GcnEvent.localizations).joinedload(
                                Localization.tags
                            ),
                            joinedload(GcnEvent.localizations).joinedload(
                                Localization.properties
                            ),
                            joinedload(GcnEvent.gcn_notices).undefer(GcnNotice.content),
                            joinedload(GcnEvent.comments),
                            joinedload(GcnEvent.detectors),
                            joinedload(GcnEvent.properties),
                            joinedload(GcnEvent.summaries),
                            joinedload(GcnEvent.gcn_triggers),
                        ],
                    ).where(GcnEvent.dateobs == dateobs)
                ).first()
                if event is None:
                    return self.error("GCN event not found", status=404)

                data = {
                    **event.to_dict(),
                    "tags": list(set(event.tags)),
                    "lightcurve": event.lightcurve,
                    "localizations": sorted(
                        (
                            {
                                **loc.to_dict(),
                                "tags": [tag.to_dict() for tag in loc.tags],
                                "properties": [
                                    properties.to_dict()
                                    for properties in loc.properties
                                ],
                                "center": loc.center,
                            }
                            for loc in event.localizations
                        ),
                        key=lambda x: x["created_at"],
                        reverse=True,
                    ),
                    "comments": sorted(
                        (
                            {
                                **{
                                    k: v
                                    for k, v in c.to_dict().items()
                                    if k != "attachment_bytes"
                                },
                                "author": {
                                    **c.author.to_dict(),
                                    "gravatar_url": c.author.gravatar_url,
                                },
                                "resourceType": "gcn_event",
                            }
                            for c in event.comments
                        ),
                        key=lambda x: x["created_at"],
                        reverse=True,
                    ),
                    "summaries": sorted(
                        (
                            {
                                **s.to_dict(),
                                "sent_by": s.sent_by.to_dict(),
                                "group": s.group.to_dict(),
                            }
                            for s in event.summaries
                        ),
                        key=lambda x: x["created_at"],
                        reverse=True,
                    ),
                    "gcn_notices": [notice.to_dict() for notice in event.gcn_notices],
                    # sort the properties by created_at date descending
                    "properties": sorted(
                        (
                            {
                                **s.to_dict(),
                            }
                            for s in event.properties
                        ),
                        key=lambda x: x["created_at"],
                        reverse=True,
                    ),
                    "gracedb_log": event.gracedb_log,
                    "gracedb_labels": event.gracedb_labels,
                }

                return self.success(data=data)

        with self.Session() as session:
            query = GcnEvent.select(
                session.user_or_token,
                options=[
                    joinedload(GcnEvent.localizations),
                    joinedload(GcnEvent.gcn_notices),
                    joinedload(GcnEvent.observationplan_requests),
                    joinedload(GcnEvent.gcn_triggers),
                ],
            )

            if partialdateobs is not None and partialdateobs != "":
                try:
                    arrow.get(partialdateobs.strip()).datetime
                    partialdateobs = partialdateobs.replace("T", " ")
                except Exception:
                    if len(partialdateobs) > 10 and partialdateobs[10] == "T":
                        partialdateobs = partialdateobs.replace("T", " ")
                partialdateobs = partialdateobs.strip().lower()
                query = query.where(
                    cast(GcnEvent.dateobs, String).like(f"{partialdateobs}%")
                    | func.lower(cast(GcnEvent.aliases, String)).like(
                        f"%{partialdateobs}%"
                    )
                )
            if start_date:
                start_date = arrow.get(start_date.strip()).datetime
                query = query.where(GcnEvent.dateobs >= start_date)
            if end_date:
                end_date = arrow.get(end_date.strip()).datetime
                query = query.where(GcnEvent.dateobs <= end_date)
            if gcn_tag_keep:
                gcn_tag_subquery = (
                    GcnTag.select(session.user_or_token)
                    .where(GcnTag.text.in_(gcn_tag_keep))
                    .subquery()
                )
                query = query.join(
                    gcn_tag_subquery, GcnEvent.dateobs == gcn_tag_subquery.c.dateobs
                )
            if gcn_tag_remove:
                gcn_tag_subquery = (
                    GcnTag.select(session.user_or_token)
                    .where(GcnTag.text.in_(gcn_tag_remove))
                    .subquery()
                )
                gcn_dateobs_query = GcnEvent.select(
                    session.user_or_token, columns=[GcnEvent.dateobs]
                ).where(GcnEvent.dateobs == gcn_tag_subquery.c.dateobs)
                gcn_dateobs_subquery = gcn_dateobs_query.subquery()

                query = query.where(GcnEvent.dateobs.notin_(gcn_dateobs_subquery))
            if localization_tag_keep:
                tag_subquery = (
                    LocalizationTag.select(session.user_or_token)
                    .where(LocalizationTag.text.in_(localization_tag_keep))
                    .subquery()
                )
                localization_id_query = (
                    Localization.select(
                        session.user_or_token, columns=[Localization.dateobs]
                    )
                    .where(Localization.id == tag_subquery.c.localization_id)
                    .subquery()
                )
                query = query.where(GcnEvent.dateobs.in_(localization_id_query))
            if localization_tag_remove:
                tag_subquery = (
                    LocalizationTag.select(session.user_or_token)
                    .where(LocalizationTag.text.in_(localization_tag_remove))
                    .subquery()
                )
                localization_id_query = (
                    Localization.select(
                        session.user_or_token, columns=[Localization.dateobs]
                    )
                    .where(Localization.id == tag_subquery.c.localization_id)
                    .subquery()
                )
                query = query.where(GcnEvent.dateobs.notin_(localization_id_query))
            if gcn_properties_filter is not None:
                for prop_filt in gcn_properties_filter:
                    prop_split = prop_filt.split(":")
                    if not (len(prop_split) == 1 or len(prop_split) == 3):
                        raise ValueError(
                            "Invalid gcnPropertiesFilter value -- property filter must have 1 or 3 values"
                        )
                    name = prop_split[0].strip()

                    properties_query = GcnProperty.select(session.user_or_token)
                    if len(prop_split) == 3:
                        value = prop_split[1].strip()
                        try:
                            value = float(value)
                        except ValueError as e:
                            raise ValueError(
                                f"Invalid GCN properties filter value: {e}"
                            )
                        op = prop_split[2].strip()
                        op_options = ["lt", "le", "eq", "ne", "ge", "gt"]
                        if op not in op_options:
                            raise ValueError(f"Invalid operator: {op}")
                        comp_function = getattr(operator, op)

                        properties_query = properties_query.where(
                            comp_function(GcnProperty.data[name], cast(value, JSONB))
                        )
                    else:
                        properties_query = properties_query.where(
                            GcnProperty.data[name].astext.is_not(None)
                        )

                    properties_subquery = properties_query.subquery()
                    query = query.join(
                        properties_subquery,
                        GcnEvent.dateobs == properties_subquery.c.dateobs,
                    )

            if localization_properties_filter is not None:
                for prop_filt in localization_properties_filter:
                    prop_split = prop_filt.split(":")
                    if not (len(prop_split) == 1 or len(prop_split) == 3):
                        raise ValueError(
                            "Invalid localizationPropertiesFilter value -- property filter must have 1 or 3 values"
                        )
                    name = prop_split[0].strip()

                    properties_query = LocalizationProperty.select(
                        session.user_or_token
                    )
                    if len(prop_split) == 3:
                        value = prop_split[1].strip()
                        try:
                            value = float(value)
                        except ValueError as e:
                            raise ValueError(
                                f"Invalid localization properties filter value: {e}"
                            )
                        op = prop_split[2].strip()
                        op_options = ["lt", "le", "eq", "ne", "ge", "gt"]
                        if op not in op_options:
                            raise ValueError(f"Invalid operator: {op}")
                        comp_function = getattr(operator, op)

                        properties_query = properties_query.where(
                            comp_function(
                                LocalizationProperty.data[name], cast(value, JSONB)
                            )
                        )
                    else:
                        properties_query = properties_query.where(
                            LocalizationProperty.data[name].astext.is_not(None)
                        )

                    properties_subquery = properties_query.subquery()
                    localizations_query = Localization.select(session.user_or_token)
                    localizations_query = localizations_query.join(
                        properties_subquery,
                        Localization.id == properties_subquery.c.localization_id,
                    )
                    localizations_subquery = localizations_query.subquery()

                    query = query.join(
                        localizations_subquery,
                        GcnEvent.dateobs == localizations_subquery.c.dateobs,
                    )

            total_matches = session.scalar(
                sa.select(sa.func.count()).select_from(query.distinct())
            )

            order_by = None
            if sort_by is not None:
                if sort_by == "dateobs":
                    order_by = (
                        [GcnEvent.dateobs]
                        if sort_order == "asc"
                        else [GcnEvent.dateobs.desc()]
                    )

            if order_by is None:
                order_by = [GcnEvent.dateobs.desc()]

            query = query.order_by(*order_by)

            if n_per_page is not None:
                query = (
                    query.distinct()
                    .limit(n_per_page)
                    .offset((page_number - 1) * n_per_page)
                )

            events = []
            for event in session.scalars(query).unique().all():
                event.gcn_notices = sorted(
                    event.gcn_notices, key=lambda notice: notice.date, reverse=True
                )
                for notice in event.gcn_notices:
                    if notice.notice_type is not None:
                        try:
                            notice.notice_type = gcn.NoticeType(notice.notice_type).name
                        except ValueError:
                            pass
                event_info = {
                    **event.to_dict(),
                    "tags": list(set(event.tags)),
                    "localizations": sorted(
                        (
                            {
                                **loc.to_dict(),
                                "tags": [tag.to_dict() for tag in loc.tags],
                            }
                            for loc in event.localizations
                        ),
                        key=lambda x: x["created_at"],
                        reverse=True,
                    ),
                }
                events.append(event_info)

            query_results = {"events": events, "totalMatches": int(total_matches)}

            return self.success(data=query_results)

    @permissions(["System admin"])
    def delete(self, dateobs):
        """
        ---
        description: Delete a GCN event
        tags:
          - gcnevents
        parameters:
          - in: path
            name: dateobs
            required: true
            schema:
              type: dateobs
        responses:
          200:
            content:
              application/json:
                schema: Success
          400:
            content:
              application/json:
                schema: Error
        """
        with self.Session() as session:
            try:
                event = session.scalars(
                    GcnEvent.select(session.user_or_token, mode="delete").where(
                        GcnEvent.dateobs == dateobs
                    )
                ).first()
                if event is None:
                    return self.error("GCN event not found", status=404)

                # get all of the skymaps on that event
                localizations = session.scalars(
                    Localization.select(session.user_or_token, mode="delete").where(
                        Localization.dateobs == dateobs
                    )
                ).all()
                for localization in localizations:
                    session.delete(localization)
                session.commit()

                # get all of the notices of the event, and delete them
                notices = session.scalars(
                    GcnNotice.select(session.user_or_token, mode="delete").where(
                        GcnNotice.dateobs == dateobs
                    )
                ).all()
                for notice in notices:
                    session.delete(notice)

                # delete all GCN tags
                tags = session.scalars(
                    GcnTag.select(session.user_or_token, mode="delete").where(
                        GcnTag.dateobs == dateobs
                    )
                ).all()
                for tag in tags:
                    session.delete(tag)
                session.commit()

                session.delete(event)
                session.commit()

                return self.success()
            except Exception as e:
                session.rollback()
                return self.error(f"Cannot delete event: {e}")


def add_tiles_and_properties_and_contour(
    localization_id,
    user_id,
    parent_session=None,
    url=None,
    notify=True,
    properties=None,
    tags=None,
):
    if parent_session is None:
        if Session.registry.has():
            session = Session()
        else:
            session = Session(bind=DBSession.session_factory.kw["bind"])
    else:
        session = parent_session

    try:
        user = session.scalar(sa.select(User).where(User.id == user_id))
        localization = session.scalar(
            sa.select(Localization).where(Localization.id == localization_id)
        )

        properties_dict, tags_list = get_skymap_properties(localization)
        if properties is not None:
            properties_dict.update(properties)
        if tags is not None:
            tags_list.extend(tags)

        properties = LocalizationProperty(
            localization_id=localization_id, sent_by_id=user.id, data=properties_dict
        )
        session.add(properties)

        tags = [
            LocalizationTag(
                localization_id=localization_id,
                text=text,
                sent_by_id=user.id,
            )
            for text in tags_list
        ]
        session.add_all(tags)

        gcn_tags = add_default_gcn_tags(user, session, localization=localization)
        if gcn_tags is not None and len(gcn_tags) > 0:
            session.add_all(gcn_tags)
            session.commit()

        if notify:
            try:
                loop = asyncio.get_event_loop()
            except Exception:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

            request_body = {
                'target_class_name': 'Localization',
                'target_id': localization_id,
            }
            IOLoop.current().run_in_executor(
                None,
                lambda: post_notification(request_body, timeout=30),
            )

        tiles = [
            LocalizationTile(
                localization_id=localization_id,
                healpix=uniq,
                probdensity=probdensity,
                dateobs=localization.dateobs,
            )
            for uniq, probdensity in zip(localization.uniq, localization.probdensity)
        ]

        if parent_session is None:
            session.add(localization)
        session.add_all(tiles)
        session.commit()

        localization = get_contour(localization)
        session.add(localization)
        session.commit()

        if url is not None:
            try:
                r = requests.get(url, allow_redirects=True, timeout=15)
                data_to_disk = r.content
                urlpath = urlsplit(url).path
                localization_name = os.path.basename(urlpath)
                if data_to_disk is not None:
                    localization.save_data(localization_name, data_to_disk)
                    session.commit()
            except Exception as e:
                log(
                    f"Localization {localization_id} URL {url} failed to download: {str(e)}."
                )

        return log(
            f"Generated tiles / properties / contour for localization {localization_id}"
        )
    except Exception as e:
        log(
            f"Unable to generate tiles / properties / contour for localization {localization_id}: {e}"
        )
        session.rollback()
    finally:
        if parent_session is None:
            session.close()
            Session.remove()


def add_default_gcn_tags(user, session, dateobs=None, localization=None):
    gcn_tags = []
    try:
        if dateobs is None and localization is None:
            return gcn_tags
        if dateobs is None:
            event = session.scalars(
                GcnEvent.select(user).where(GcnEvent.dateobs == localization.dateobs)
            ).first()
        else:
            event = session.scalars(
                GcnEvent.select(user).where(GcnEvent.dateobs == dateobs)
            ).first()
        event_notice_types = [notice.notice_type for notice in event.gcn_notices]
        event_tags = event.tags
        if localization is not None:
            localization_tags = [tag.text for tag in localization.tags]
        else:
            localization_tags = []

        default_gcn_tags = (
            (
                session.scalars(
                    DefaultGcnTag.select(
                        user,
                    )
                )
            )
            .unique()
            .all()
        )

        for default_gcn_tag in default_gcn_tags:
            try:
                filters = default_gcn_tag.filters
                if len(filters.get('gcn_tags', [])) > 0:
                    if not any([tag in event_tags for tag in filters['gcn_tags']]):
                        continue
                if len(filters.get('notice_types', [])) > 0:
                    if not any(
                        [
                            notice_type in event_notice_types
                            for notice_type in filters['notice_type']
                        ]
                    ):
                        continue
                if len(filters.get('localization_tags', [])) > 0:
                    if not any(
                        [
                            tag in localization_tags
                            for tag in filters['localization_tags']
                        ]
                    ):
                        continue
                tag_name = default_gcn_tag.default_tag_name
                if tag_name not in event_tags and tag_name not in gcn_tags:
                    gcn_tags.append(tag_name)
            except Exception:
                pass

        gcn_tags = [
            GcnTag(
                text=text,
                dateobs=event.dateobs,
                sent_by_id=user.id,
            )
            for text in gcn_tags
        ]
    except Exception as e:
        log(f"Unable to add default GCN tags: {str(e)}")
        gcn_tags = []

    return gcn_tags


def add_observation_plans(localization_id, user_id, parent_session=None):
    if parent_session is None:
        if Session.registry.has():
            session = Session()
        else:
            session = Session(bind=DBSession.session_factory.kw["bind"])
    else:
        session = parent_session

    try:
        user = session.scalar(sa.select(User).where(User.id == user_id))
        localization = session.scalars(
            sa.select(Localization).where(Localization.id == localization_id)
        ).first()
        dateobs = localization.dateobs
        localization_tags = [
            tags.text
            for tags in session.scalars(
                sa.select(LocalizationTag).where(
                    LocalizationTag.localization_id == localization_id
                )
            ).all()
        ]

        default_observation_plans = (
            session.scalars(DefaultObservationPlanRequest.select(user)).unique().all()
        )
        gcn_observation_plans = []
        for plan in default_observation_plans:
            gcn_observation_plan = {
                'allocation_id': plan.allocation_id,
                'filters': plan.filters,
                'payload': plan.payload,
                'default': plan.id,
            }
            gcn_observation_plans.append(gcn_observation_plan)

        event = session.scalars(
            GcnEvent.select(user).where(GcnEvent.dateobs == dateobs)
        ).first()
        start_date = str(datetime.datetime.utcnow()).replace("T", "")

        for ii, gcn_observation_plan in enumerate(gcn_observation_plans):
            allocation_id = gcn_observation_plan['allocation_id']
            allocation = session.scalars(
                Allocation.select(user).where(Allocation.id == allocation_id)
            ).first()
            if allocation is not None:
                end_date = allocation.instrument.telescope.next_sunrise()
                if end_date is None:
                    end_date = str(
                        datetime.datetime.utcnow() + datetime.timedelta(days=1)
                    ).replace("T", "")
                else:
                    end_date = Time(end_date, format='jd').iso

                payload = {
                    **gcn_observation_plan['payload'],
                    'start_date': start_date,
                    'end_date': end_date,
                    'queue_name': f'{allocation.instrument.name}-{start_date}-{ii}',
                }
                if 'default' in gcn_observation_plan:
                    payload['default'] = gcn_observation_plan['default']
                plan = {
                    'payload': payload,
                    'allocation_id': allocation.id,
                    'gcnevent_id': event.id,
                    'localization_id': localization_id,
                }

                if 'filters' in gcn_observation_plan:
                    filters = gcn_observation_plan['filters']
                    if filters is not None:
                        if 'gcn_notices' in filters and len(filters['gcn_notices']) > 0:
                            gcn_notice_filter = False
                            for notice in event.gcn_notices:
                                if notice.notice_type is not None:
                                    try:
                                        notice.notice_type = gcn.NoticeType(
                                            notice.notice_type
                                        ).name
                                    except ValueError:
                                        pass
                                    if notice.notice_type in filters['gcn_notices']:
                                        gcn_notice_filter = True
                                        break
                            if not gcn_notice_filter:
                                continue

                        if 'gcn_tags' in filters and len(filters['gcn_tags']) > 0:
                            intersection = list(
                                set(event.tags) & set(filters["gcn_tags"])
                            )
                            if len(intersection) == 0:
                                continue

                        if (
                            "localization_tags" in filters
                            and len(filters["localization_tags"]) > 0
                        ):
                            intersection = list(
                                set(localization_tags)
                                & set(filters["localization_tags"])
                            )
                            if len(intersection) == 0:
                                continue

                post_observation_plan(
                    plan,
                    user_id=user.id,
                    session=session,
                    default_plan=True,
                    asynchronous=False,
                )
        log(f"Triggered observation plans for localization {localization_id}")
    except Exception as e:
        log(
            f"Unable to trigger observation plans for localization {localization_id}: {e}"
        )
    finally:
        if parent_session is None:
            session.close()
            Session.remove()


def add_tiles_properties_contour_and_obsplan(
    localization_id,
    user_id,
    parent_session=None,
    url=None,
    notify=True,
    properties=None,
    tags=None,
):
    if parent_session is None:
        if Session.registry.has():
            session = Session()
        else:
            session = Session(bind=DBSession.session_factory.kw["bind"])
    else:
        session = parent_session

    try:
        add_tiles_and_properties_and_contour(
            localization_id,
            user_id,
            session,
            url=url,
            notify=notify,
            properties=properties,
            tags=tags,
        )
        add_observation_plans(localization_id, user_id, session)
    except Exception as e:
        log(
            f"Unable to generate tiles / properties / observation plans / contour for localization {localization_id}: {e}"
        )
    finally:
        if parent_session is None:
            session.close()
            Session.remove()


class LocalizationHandler(BaseHandler):
    @auth_or_token
    async def get(self, dateobs, localization_name):
        """
        ---
        description: Retrieve a GCN localization
        tags:
          - localizations
        parameters:
          - in: path
            name: dateobs
            required: true
            schema:
              type: dateobs
          - in: path
            name: localization_name
            required: true
            schema:
              type: localization_name
          - in: query
            name: include2DMap
            nullable: true
            schema:
              type: boolean
            description: |
              Boolean indicating whether to include flatted skymap. Defaults to
              false.

        responses:
          200:
            content:
              application/json:
                schema: LocalizationHandlerGet
          400:
            content:
              application/json:
                schema: Error
        """

        include_2D_map = self.get_query_argument("include2DMap", False)

        with self.Session() as session:
            localization = session.scalars(
                Localization.select(session.user_or_token).where(
                    Localization.dateobs == dateobs,
                    Localization.localization_name == localization_name,
                )
            ).first()
            if localization is None:
                return self.error("Localization not found", status=404)

            if include_2D_map:
                data = {
                    **localization.to_dict(),
                    "flat_2d": localization.flat_2d,
                    "contour": localization.contour,
                }
            else:
                data = {
                    **localization.to_dict(),
                    "contour": localization.contour,
                }
            return self.success(data=data)

    @auth_or_token
    def delete(self, dateobs, localization_name):
        """
        ---
        description: Delete a GCN localization
        tags:
          - localizations
        parameters:
          - in: path
            name: dateobs
            required: true
            schema:
              type: string
          - in: path
            name: localization_name
            required: true
            schema:
              type: string
        responses:
          200:
            content:
              application/json:
                schema: Success
          400:
            content:
              application/json:
                schema: Error
        """

        with self.Session() as session:
            localization = session.scalars(
                Localization.select(session.user_or_token, mode="delete").where(
                    Localization.dateobs == dateobs,
                    Localization.localization_name == localization_name,
                )
            ).first()

            if localization is None:
                return self.error("Localization not found", status=404)

            dateobs = localization.dateobs

            session.delete(localization)
            session.commit()

            self.push(
                action="skyportal/REFRESH_GCN_EVENT",
                payload={"gcnEvent_dateobs": dateobs},
            )

            return self.success()


class LocalizationNoticeHandler(BaseHandler):
    @auth_or_token
    async def post(self, dateobs, notice_id):
        # first get the notice, if it exists
        with self.Session() as session:
            gcn_notice = session.scalars(
                GcnNotice.select(session.user_or_token).where(
                    GcnNotice.dateobs == dateobs, GcnNotice.id == notice_id
                )
            ).first()

            if gcn_notice is None:
                return self.error("Notice not found", status=404)

            root, notice_type = None, None

            # try reading xml notice
            try:
                root = lxml.etree.fromstring(gcn_notice.content)
                notice_type = gcn_notice.notice_type
            except lxml.etree.XMLSyntaxError:
                pass

            # try reading json notice
            if root is None:
                try:
                    root = json.loads(gcn_notice.content.decode('utf8'))
                    notice_type = None
                except json.JSONDecodeError:
                    pass

            if root is None:
                return self.error(f"Could not read the content of notice {notice_id}")

            status, skymap_metadata = get_skymap_metadata(root, notice_type)
            if status == "unavailable":
                return self.error(
                    "Skymap present in notice isn't available (yet)", status=404
                )
            elif status in ["available", "cone"]:
                if (
                    not isinstance(skymap_metadata, dict)
                    or "name" not in skymap_metadata
                ):
                    return self.error(
                        f"Could not retrieve the skymap's name for notice {notice_id}"
                    )
                localization = session.scalars(
                    Localization.select(session.user_or_token).where(
                        Localization.dateobs == dateobs,
                        Localization.localization_name == skymap_metadata["name"],
                    )
                ).first()
                if localization is not None:
                    return self.error("Localization already exists", status=409)
                else:
                    try:
                        post_skymap_from_notice(
                            dateobs,
                            gcn_notice.id,
                            self.associated_user_object.id,
                            session,
                        )
                        flow = Flow()
                        flow.push(
                            '*',
                            "skyportal/REFRESH_GCN_EVENT",
                            payload={"gcnEvent_dateobs": dateobs},
                        )
                        return self.success()
                    except Exception as e:
                        return self.error(f"Error posting skymap from notice: {e}")
            elif status == "retracted":
                return self.error(
                    "Notice is for a retraction, no skymap needs to be posted",
                    status=404,
                )
            else:
                return self.error("Notice is missing skymap metadata", status=404)


class LocalizationPropertiesHandler(BaseHandler):
    @auth_or_token
    async def get(self):
        """
        ---
        description: Get all Localization properties
        tags:
          - photometry
        responses:
          200:
            content:
              application/json:
                schema: Success
          400:
            content:
              application/json:
                schema: Error
        """

        with self.Session() as session:
            properties = (
                session.scalars(
                    sa.select(
                        sa.func.jsonb_object_keys(LocalizationProperty.data)
                    ).distinct()
                )
                .unique()
                .all()
            )
            return self.success(data=sorted(properties))


class LocalizationTagsHandler(BaseHandler):
    @auth_or_token
    async def get(self):
        """
        ---
        description: Get all Localization tags
        tags:
          - photometry
        responses:
          200:
            content:
              application/json:
                schema: Success
          400:
            content:
              application/json:
                schema: Error
        """

        with self.Session() as session:
            tags = (
                session.scalars(sa.select(LocalizationTag.text).distinct())
                .unique()
                .all()
            )
            return self.success(data=tags)


def nb_obs_to_word(nb_obs):
    if nb_obs < 1:
        raise ValueError('nb_obs must be >= 1')
    if nb_obs == 1:
        return 'once'
    elif nb_obs == 2:
        return 'twice'
    elif nb_obs > 2:
        return f'{nb_obs} times'


def add_gcn_summary(
    summary_id,
    user_id,
    user_accessible_group_ids,
    dateobs,
    title,
    number,
    subject,
    user_ids,
    group_id,
    start_date,
    end_date,
    localization_name,
    localization_cumprob=0.90,
    number_of_detections=1,
    number_of_observations=1,
    show_sources=True,
    show_galaxies=False,
    show_observations=False,
    no_text=False,
    photometry_in_window=True,
    stats_method='python',
    instrument_ids=None,
    acknowledgements=None,
):
    if Session.registry.has():
        session = Session()
    else:
        session = Session(bind=DBSession.session_factory.kw["bind"])

    try:
        user = session.query(User).get(user_id)
        session.user_or_token = user

        gcn_summary = session.query(GcnSummary).get(summary_id)
        group = session.query(Group).get(group_id)
        event = session.query(GcnEvent).filter(GcnEvent.dateobs == dateobs).first()
        localization = (
            session.query(Localization)
            .filter(
                Localization.dateobs == dateobs,
                Localization.localization_name == localization_name,
            )
            .first()
        )

        start_date_mjd = Time(arrow.get(start_date).datetime).mjd
        end_date_mjd = Time(arrow.get(end_date).datetime).mjd

        contents = []
        if not no_text:
            header_text = []
            header_text.append(f"""TITLE: {title.upper()}\n""")
            if number is not None:
                header_text.append(f"""NUMBER: {number}\n""")
            header_text.append(f"""SUBJECT: {subject[0].upper()+subject[1:]}\n""")
            now_date = astropy.time.Time.now()
            header_text.append(f"""DATE: {now_date}\n""")

            if user.affiliations is not None and len(user.affiliations) > 0:
                affiliations = ", ".join(user.affiliations)
            else:
                affiliations = "..."

            # add a "FROM full name and affiliation"
            from_str = (
                f"""FROM:  {user.first_name} {user.last_name} at {affiliations}"""
            )
            if user.contact_email is not None:
                from_str += f""" <{user.contact_email}>\n"""
            header_text.append(from_str)

            if len(user_ids) > 0:
                users = []
                for mentioned_user_id in user_ids:
                    mentioned_user = session.query(User).get(mentioned_user_id)
                    if mentioned_user is not None:
                        users.append(mentioned_user)

                users_txt = []
                for mentioned_user in users:
                    if (
                        mentioned_user.first_name is not None
                        and mentioned_user.last_name is not None
                    ):
                        if (
                            mentioned_user.affiliations is not None
                            and len(mentioned_user.affiliations) > 0
                        ):
                            affiliations = ", ".join(mentioned_user.affiliations)
                        else:
                            affiliations = "..."

                        users_txt.append(
                            f"""{mentioned_user.first_name[0].upper()}. {mentioned_user.last_name} ({affiliations})"""
                        )
                # create a string of all users, with 5 users per line
                users_txt = "\n".join(
                    [
                        ", ".join(users_txt[i : i + 5])
                        for i in range(0, len(users_txt), 5)
                    ]
                )
                header_text.append(f"""\n{users_txt}\n""")

            header_text.append(f"""\non behalf of the {group.name}, report:\n""")
            contents.extend(header_text)

        if show_sources:
            sources_text = []
            source_page_number = 1
            sources = []
            while True:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                # get the sources in the event
                coroutine = get_sources(
                    user_id=user.id,
                    session=session,
                    group_ids=[group.id],
                    user_accessible_group_ids=user_accessible_group_ids,
                    first_detected_date=start_date,
                    last_detected_date=end_date,
                    localization_dateobs=dateobs,
                    localization_name=localization_name,
                    localization_cumprob=localization_cumprob,
                    number_of_detections=number_of_detections,
                    page_number=source_page_number,
                    num_per_page=MAX_SOURCES_PER_PAGE,
                )
                sources_data = loop.run_until_complete(coroutine)
                sources.extend(sources_data['sources'])
                source_page_number += 1

                if len(sources_data['sources']) < MAX_SOURCES_PER_PAGE:
                    break
            if len(sources) > 0:
                obj_ids = [source['id'] for source in sources]
                sources_with_status = session.scalars(
                    SourcesConfirmedInGCN.select(user).where(
                        SourcesConfirmedInGCN.obj_id.in_(obj_ids),
                        SourcesConfirmedInGCN.dateobs == dateobs,
                    )
                ).all()

                ids, tns_name, ras, decs, redshifts, status, explanation = (
                    [],
                    [],
                    [],
                    [],
                    [],
                    [],
                    [],
                )
                for source in sources:
                    ids.append(source['id'] if 'id' in source else None)
                    tns_name.append(
                        source['tns_name'] if 'tns_name' in source else None
                    )
                    ras.append(np.round(source['ra'], 5) if 'ra' in source else None)
                    decs.append(np.round(source['dec'], 5) if 'dec' in source else None)
                    redshift = source['redshift'] if 'redshift' in source else None
                    if 'redshift_error' in source and redshift is not None:
                        if source['redshift_error'] is not None:
                            redshift = f"{redshift}±{source['redshift_error']}"
                    redshifts.append(redshift)
                    source_in_gcn = next(
                        (
                            source_in_gcn
                            for source_in_gcn in sources_with_status
                            if source_in_gcn.obj_id == source['id']
                        ),
                        None,
                    )
                    if source_in_gcn is not None:
                        status.append(source_in_gcn.confirmed)
                        explanation.append(source_in_gcn.explanation)
                    else:
                        status.append(None)
                        explanation.append(None)

                df = pd.DataFrame(
                    {
                        "id": ids,
                        "tns": tns_name,
                        "ra": ras,
                        "dec": decs,
                        "redshift": redshifts,
                        "status": status,
                        "comment": explanation,
                    }
                )

                df_rejected = df[
                    (
                        df['id'].isin(
                            [
                                source.obj_id
                                for source in sources_with_status
                                if source.confirmed is False
                            ]
                        )
                    )
                ]

                df_confirmed_or_unknown = df[(~df['id'].isin(df_rejected['id']))]

                df_confirmed_or_unknown = df_confirmed_or_unknown.drop(
                    columns=['status']
                )
                df_rejected = df_rejected.drop(columns=['status'])
                df = df.fillna("--")

                sources_text.append(
                    f"\nFound {len(sources)} {'sources' if len(sources) > 1 else 'source'} in the event's localization, {df_rejected.shape[0]} of which {'have' if df_rejected.shape[0]>1 else 'has'} been rejected after characterization:\n"
                ) if not no_text else None

                if df_confirmed_or_unknown.shape[0] > 0:
                    if not no_text:
                        sources_text.append("Sources:")
                    sources_text.append(
                        tabulate(
                            df_confirmed_or_unknown,
                            headers='keys',
                            tablefmt='psql',
                            showindex=False,
                            floatfmt=".4f",
                        )
                        + "\n"
                    )
                if df_rejected.shape[0] > 0:
                    if not no_text:
                        sources_text.append("Rejected sources:")
                    sources_text.append(
                        tabulate(
                            df_rejected,
                            headers='keys',
                            tablefmt='psql',
                            showindex=False,
                            floatfmt=".4f",
                        )
                        + "\n"
                    )

                for source in sources:
                    stmt = Photometry.select(user).where(
                        Photometry.obj_id == source['id']
                    )
                    if photometry_in_window:
                        stmt = stmt.where(
                            Photometry.mjd >= start_date_mjd,
                            Photometry.mjd <= end_date_mjd,
                        )
                    photometry = session.scalars(stmt).all()
                    if len(photometry) > 0:
                        sources_text.append(
                            f"""\nPhotometry for source {source['id']}:\n"""
                        ) if not no_text else None
                        mjds, mags, filters, origins, instruments = (
                            [],
                            [],
                            [],
                            [],
                            [],
                        )
                        for phot in photometry:
                            phot = serialize(phot, 'ab', 'mag')
                            mjds.append(phot['mjd'] if 'mjd' in phot else None)
                            if (
                                'mag' in phot
                                and 'magerr' in phot
                                and phot['mag'] is not None
                                and phot['magerr'] is not None
                            ):
                                mags.append(
                                    f"{np.round(phot['mag'],2)}±{np.round(phot['magerr'],2)}"
                                )
                            elif (
                                'limiting_mag' in phot
                                and phot['limiting_mag'] is not None
                            ):
                                mags.append(f"< {np.round(phot['limiting_mag'], 1)}")
                            else:
                                mags.append(None)
                            filters.append(phot['filter'] if 'filter' in phot else None)
                            origins.append(phot['origin'] if 'origin' in phot else None)
                            instruments.append(
                                phot['instrument_name']
                                if 'instrument_name' in phot
                                else None
                            )
                        df_phot = pd.DataFrame(
                            {
                                "mjd": mjds,
                                "mag±err (ab)": mags,
                                "filter": filters,
                                "origin": origins,
                                "instrument": instruments,
                            }
                        )
                        if no_text:
                            df_phot.insert(
                                loc=0,
                                column='obj_id',
                                value=[p.obj_id for p in photometry],
                            )
                        df_phot = df_phot.fillna("--")
                        sources_text.append(
                            tabulate(
                                df_phot,
                                headers='keys',
                                tablefmt='psql',
                                showindex=False,
                                floatfmt=".5f",
                            )
                            + "\n"
                        )
            contents.extend(sources_text)

        if show_galaxies:
            galaxies_text = []
            galaxies_page_number = 1
            galaxies = []
            # get the galaxies in the event
            while True:
                galaxies_data = get_galaxies(
                    session,
                    localization_dateobs=event.dateobs,
                    localization_name=localization_name,
                    localization_cumprob=localization_cumprob,
                    page_number=galaxies_page_number,
                    num_per_page=MAX_GALAXIES,
                    return_probability=True,
                )
                galaxies.extend(galaxies_data['galaxies'])
                galaxies_page_number += 1
                if len(galaxies_data['galaxies']) < MAX_GALAXIES:
                    break
            if len(galaxies) > 0:
                galaxies_text.append(
                    f"""\nFound {len(galaxies)} {'galaxies' if len(galaxies) > 1 else 'galaxy'} in the event's localization:\n"""
                ) if not no_text else None
                names, ras, decs, distmpcs, magks, mag_nuvs, mag_w1s, probabilities = (
                    [],
                    [],
                    [],
                    [],
                    [],
                    [],
                    [],
                    [],
                )
                for galaxy in galaxies:
                    if galaxy['probability'] is None or galaxy['probability'] == 0:
                        continue

                    names.append(galaxy['name'] if 'name' in galaxy else None)
                    ras.append(galaxy['ra'] if 'ra' in galaxy else None)
                    decs.append(galaxy['dec'] if 'dec' in galaxy else None)
                    distmpcs.append(galaxy['distmpc'] if 'distmpc' in galaxy else None)
                    magks.append(galaxy['magk'] if 'magk' in galaxy else None)
                    mag_nuvs.append(galaxy['mag_nuv'] if 'mag_nuv' in galaxy else None)
                    mag_w1s.append(galaxy['mag_w1'] if 'mag_w1' in galaxy else None)
                    probabilities.append(
                        galaxy['probability'] if 'probability' in galaxy else None
                    )
                df = pd.DataFrame(
                    {
                        "name": names,
                        "ra": ras,
                        "dec": decs,
                        "distmpc": distmpcs,
                        "magk": magks,
                        "mag_nuv": mag_nuvs,
                        "mag_w1": mag_w1s,
                        "probability": probabilities,
                    }
                )
                df.sort_values("probability", inplace=True, ascending=False)
                df = df[df["probability"] >= np.max(df["probability"]) * 0.01]
                df = df.fillna("--")
                galaxies_text.append(
                    tabulate(
                        df,
                        headers=[
                            'Galaxy',
                            'RA [deg]',
                            'Dec [deg]',
                            'Distance [Mpc]',
                            'm_Ks [mag]',
                            'm_NUV [mag]',
                            'm_W1 [mag]',
                            'dP_dV',
                        ],
                        tablefmt='psql',
                        showindex=False,
                        floatfmt=(str, ".4f", ".4f", ".1f", ".1f", ".1f", ".1f", ".3e"),
                    )
                    + "\n"
                )
            contents.extend(galaxies_text)

            if localization is not None:
                distmean, distsigma = localization.marginal_moments
                if (distmean is not None) and (distsigma is not None):
                    min_distance = np.max([distmean - 3 * distsigma, 0])
                    max_distance = np.min([distmean + 3 * distsigma, 10000])
                    try:
                        completeness = get_galaxies_completeness(
                            galaxies, dist_min=min_distance, dist_max=max_distance
                        )
                    except Exception:
                        completeness = None

                    if completeness is not None and not no_text:
                        completeness_text = f"\n\nThe estimated mass completeness of the catalog for the skymap distance is ~{int(round(completeness*100,0))}%. This calculation was made by comparing the total mass within the catalog to a stellar mass function described by a Schechter function in the range {distmean:.1f} ± {distsigma:.1f} Mpc (within 3 sigma of the skymap).\n"
                        contents.append(completeness_text)

        if show_observations:
            # get the executed obs, by instrument
            observations_text = []
            start_date = arrow.get(start_date).datetime
            end_date = arrow.get(end_date).datetime

            if instrument_ids is not None:
                stmt = Instrument.select(user).where(Instrument.id.in_(instrument_ids))
            else:
                stmt = Instrument.select(user).options(joinedload(Instrument.telescope))
            instruments = session.scalars(stmt).all()
            if instruments is not None:
                for instrument in instruments:
                    data = get_observations(
                        session,
                        start_date,
                        end_date,
                        telescope_name=instrument.telescope.name,
                        instrument_name=instrument.name,
                        localization_dateobs=dateobs,
                        localization_name=localization_name,
                        localization_cumprob=localization_cumprob,
                        min_observations_per_field=number_of_observations,
                        return_statistics=True,
                        stats_method=stats_method,
                        n_per_page=MAX_OBSERVATIONS,
                        page_number=1,
                        sort_by="obstime",
                        sort_order="asc",
                    )

                    observations = data["observations"]
                    num_observations = len(observations)
                    if num_observations > 0:
                        start_observation = astropy.time.Time(
                            min(obs["obstime"] for obs in observations),
                            format='datetime',
                        )
                        unique_filters = list({obs["filt"] for obs in observations})
                        total_time = sum(obs["exposure_time"] for obs in observations)
                        probability = data["probability"]
                        area = data["area"]

                        dt = start_observation.datetime - event.dateobs
                        before_after = "after" if dt.total_seconds() > 0 else "before"
                        observations_text.append(
                            f"""\n\n{instrument.telescope.name} - {instrument.name}:\n\nWe observed the localization region of {event.gcn_notices[0].stream} trigger {astropy.time.Time(event.dateobs, format='datetime').isot} UTC.  We obtained a total of {num_observations} images covering {",".join(unique_filters)} bands for a total of {total_time} seconds. The observations covered {area:.1f} square degrees of the localization at least {nb_obs_to_word(number_of_observations)}, beginning at {start_observation.isot} ({humanize.naturaldelta(dt)} {before_after} the trigger time). Using the {localization_name} skymap, this corresponds to ~{int(100 * probability)}% of the probability enclosed in the localization region.\n"""
                        ) if not no_text else None
                        t0s, mjds, ras, decs, filters, exposures, limmags = (
                            [],
                            [],
                            [],
                            [],
                            [],
                            [],
                            [],
                        )
                        for obs in observations:
                            t0s.append(
                                (obs["obstime"] - event.dateobs)
                                / datetime.timedelta(hours=1)
                                if "obstime" in obs
                                else None
                            )
                            mjds.append(
                                astropy.time.Time(obs["obstime"], format='datetime').mjd
                                if "obstime" in obs
                                else None
                            )
                            ras.append(
                                obs['field']["ra"] if "ra" in obs['field'] else None
                            )
                            decs.append(
                                obs['field']["dec"] if "dec" in obs['field'] else None
                            )
                            filters.append(obs["filt"] if "filt" in obs else None)
                            exposures.append(
                                obs["exposure_time"] if "exposure_time" in obs else None
                            )
                            limmags.append(obs["limmag"] if "limmag" in obs else None)
                        df_obs = pd.DataFrame(
                            {
                                "T-T0 (hr)": t0s,
                                "mjd": mjds,
                                "ra": ras,
                                "dec": decs,
                                "filter": filters,
                                "exposure": exposures,
                                "limmag (ab)": limmags,
                            }
                        )
                        if no_text:
                            df_obs.insert(
                                loc=0,
                                column="tel/inst",
                                value=[
                                    f"{instrument.telescope.name}/{instrument.name}"
                                    for obs in observations
                                ],
                            )
                        df_obs = df_obs.fillna("--")
                        floatfmt = [".2f", ".5f", ".5f", ".5f", "%s", "%d", ".2f"]
                        if no_text:
                            floatfmt.insert(0, "%s")

                        observations_text.append(
                            tabulate(
                                df_obs,
                                headers='keys',
                                tablefmt='psql',
                                showindex=False,
                                floatfmt=floatfmt,
                            )
                            + "\n"
                        )
                if len(observations_text) > 0 and not no_text:
                    observations_text.insert(0, "\nObservations:")

                if len(observations_text) > 0:
                    contents.extend(observations_text)

        if not no_text and acknowledgements is not None and len(acknowledgements) > 0:
            contents.append("\n" + acknowledgements)
        gcn_summary.text = "\n".join(contents)
        session.commit()

        flow = Flow()
        flow.push(
            user_id='*',
            action_type="skyportal/REFRESH_GCN_EVENT",
            payload={"gcnEvent_dateobs": event.dateobs},
        )

        notification = UserNotification(
            user=user,
            text=f"GCN summary *{gcn_summary.title}* on *{event.dateobs}* created.",
            notification_type="gcn_summary",
            url=f"/gcn_events/{event.dateobs}",
        )
        session.add(notification)
        session.commit()

        log(f"Successfully generated GCN summary {gcn_summary.id}")

    except Exception as e:
        try:
            gcn_summary = session.query(GcnSummary).get(summary_id)
            gcn_summary.text = "Failed to generate summary."
            session.commit()
        except Exception:
            pass
        log(f"Unable to create GCN summary: {e}")
        raise e
    finally:
        session.close()
        Session.remove()


class GcnSummaryHandler(BaseHandler):
    @auth_or_token
    async def post(self, dateobs, summary_id=None):
        """
        ---
          description: Post a summary of a GCN event.
          tags:
            - gcnsummarys
          parameters:
            - in: body
              name: title
              schema:
                type: string
            - in: body
              name: number
              schema:
                type: string
            - in: body
              name: subject
              schema:
                type: string
            - in: body
              name: userIds
              schema:
                type: string
              description: User ids to mention in the summary. Comma-separated.
            - in: body
              name: groupId
              required: true
              schema:
                type: string
              description: id of the group that creates the summary.
            - in: body
              name: startDate
              required: true
              schema:
                type: string
              description: Filter by start date
            - in: body
              name: endDate
              required: true
              schema:
                type: string
              description: Filter by end date
            - in: body
              name: localizationName
              schema:
                type: string
              description: Name of localization / skymap to use.
            - in: body
              name: localizationCumprob
              schema:
                type: number
              description: Cumulative probability up to which to include fields. Defaults to 0.95.
            - in: body
              name: numberDetections
              nullable: true
              schema:
                type: number
              description: Return only sources who have at least numberDetections detections. Defaults to 2.
            - in: body
              name: showSources
              required: true
              schema:
                type: bool
              description: Show sources in the summary
            - in: body
              name: showGalaxies
              required: true
              schema:
                type: bool
              description: Show galaxies in the summary
            - in: body
              name: showObservations
              required: true
              schema:
                type: bool
              description: Show observations in the summary
            - in: body
              name: noText
              schema:
                type: bool
              description: Do not include text in the summary, only tables.
            - in: body
              name: photometryInWindow
              schema:
                type: bool
              description: Limit photometry to that within startDate and endDate.
            - in: body
              name: statsMethod
              schema:
                type: string
              description: Method to use for calculating statistics. Defaults to python. Options are python and db.
            - in: body
              name: instrumentIds
              schema:
                type: string
              description: List of instrument ids to include in the summary. Defaults to all instruments if not specified.
            - in: body
              name: acknowledgements
              schema:
                type: string
              description: Acknowledgements to include in the summary.

          responses:
            200:
              content:
                application/json:
                  schema:
                    allOf:
                      - $ref: '#/components/schemas/Success'
                      - type: object
                        properties:
                          data:
                            type: string
                            description: GCN summary
            400:
              content:
                application/json:
                  schema: Error
        """

        data = self.get_json()
        title = data.get("title", None)
        number = data.get("number", None)
        subject = data.get("subject")
        user_ids = data.get("userIds", None)
        group_id = data.get("groupId", None)
        start_date = data.get("startDate", None)
        end_date = data.get("endDate", None)
        localization_name = data.get("localizationName", None)
        localization_cumprob = data.get("localizationCumprob", 0.95)
        number_of_detections = data.get("numberDetections", 2)
        number_of_observations = data.get("numberObservations", 1)
        show_sources = data.get("showSources", False)
        show_galaxies = data.get("showGalaxies", False)
        show_observations = data.get("showObservations", False)
        no_text = data.get("noText", False)
        photometry_in_window = data.get("photometryInWindow", False)
        stats_method = data.get("statsMethod", "python")
        instrument_ids = data.get("instrumentIds", None)
        acknowledgements = data.get("acknowledgements", None)

        class Validator(Schema):
            start_date = UTCTZnaiveDateTime(required=False, missing=None)
            end_date = UTCTZnaiveDateTime(required=False, missing=None)
            number_of_detections = Integer(
                required=False, missing=2, validate=validate.Range(min=1)
            )
            number_of_observations = Integer(
                required=False, missing=1, validate=validate.Range(min=1)
            )

        validator_instance = Validator()
        params_to_be_validated = {}
        if start_date is not None:
            params_to_be_validated['start_date'] = start_date
        if end_date is not None:
            params_to_be_validated['end_date'] = end_date
        if number_of_detections is not None:
            params_to_be_validated['number_of_detections'] = number_of_detections
        if number_of_observations is not None:
            params_to_be_validated['number_of_observations'] = number_of_observations

        try:
            validated = validator_instance.load(params_to_be_validated)
        except ValidationError as e:
            return self.error(f'Error parsing query params: {e.args[0]}.')

        start_date = validated['start_date']
        end_date = validated['end_date']
        number_of_detections = validated['number_of_detections']
        number_of_observations = validated['number_of_observations']

        if title is None:
            return self.error("Title is required")

        if group_id is None:
            return self.error("Group ID is required")

        if stats_method not in ["db", "python"]:
            return self.error(
                "statsMethod for observations querying must be 'db' or 'python'"
            )

        if instrument_ids is not None:
            try:
                instrument_ids = [
                    int(instrument_id) for instrument_id in instrument_ids
                ]
                if len(instrument_ids) == 0:
                    instrument_ids = None
            except ValueError:
                return self.error("Instrument IDs must be a list of integers")

        try:
            number_of_detections = int(number_of_detections)
        except ValueError:
            return self.error("numberDetections must be an integer")

        if not no_text:
            if number is not None:
                try:
                    number = int(number)
                except ValueError:
                    return self.error("Number must be an integer")
            if subject is None:
                return self.error("Subject is required")
            if user_ids is not None:
                try:
                    if isinstance(user_ids, list):
                        user_ids = [int(user_id) for user_id in user_ids]
                    else:
                        user_ids = [int(user_ids)]
                except ValueError:
                    return self.error("User IDs must be integers")
            else:
                user_ids = []

            if acknowledgements is not None:
                acknowledgements = acknowledgements.strip('"')
                if len(acknowledgements) == 0:
                    acknowledgements = None

        with self.Session() as session:
            stmt = GcnEvent.select(session.user_or_token).where(
                GcnEvent.dateobs == dateobs
            )
            event = session.scalars(stmt).first()

            if event is None:
                return self.error("Event not found", status=404)

            stmt = Group.select(session.user_or_token).where(Group.id == group_id)
            group = session.scalars(stmt).first()
            if group is None:
                return self.error(f"Group not found with ID {group_id}")

            # verify that the user doesn't already have a summary with this title for this event
            stmt = GcnSummary.select(session.user_or_token, mode="read").where(
                GcnSummary.dateobs == dateobs,
                GcnSummary.title == title,
                GcnSummary.group_id == group_id,
                GcnSummary.sent_by_id == self.associated_user_object.id,
            )
            existing_summary = session.scalars(stmt).first()
            if existing_summary is not None:
                return self.error(
                    "A summary with the same title, group, and event already exists for this user"
                )

            gcn_summary = GcnSummary(
                dateobs=event.dateobs,
                title=title,
                text="pending",
                sent_by_id=self.associated_user_object.id,
                group_id=group_id,
            )
            session.add(gcn_summary)
            session.commit()

            summary_id = gcn_summary.id
            user_id = self.associated_user_object.id
            user_accessible_group_ids = [
                group.id for group in self.associated_user_object.accessible_groups
            ]

            try:
                IOLoop.current().run_in_executor(
                    None,
                    lambda: add_gcn_summary(
                        summary_id=summary_id,
                        user_id=user_id,
                        user_accessible_group_ids=user_accessible_group_ids,
                        dateobs=dateobs,
                        title=title,
                        number=number,
                        subject=subject,
                        user_ids=user_ids,
                        group_id=group_id,
                        start_date=start_date,
                        end_date=end_date,
                        localization_name=localization_name,
                        localization_cumprob=localization_cumprob,
                        number_of_detections=number_of_detections,
                        number_of_observations=number_of_observations,
                        show_sources=show_sources,
                        show_galaxies=show_galaxies,
                        show_observations=show_observations,
                        no_text=no_text,
                        photometry_in_window=photometry_in_window,
                        stats_method=stats_method,
                        instrument_ids=instrument_ids,
                        acknowledgements=acknowledgements,
                    ),
                )
                return self.success({"id": summary_id})
            except Exception as e:
                return self.error(f"Error generating summary: {e}")

    @auth_or_token
    def get(self, dateobs, summary_id):
        """
        ---
        description: Retrieve a GCN summary
        tags:
          - gcn
        parameters:
          - in: path
            name: dateobs
            required: true
            schema:
              type: string
          - in: path
            name: summary_id
            required: true
            schema:
              type: integer
        responses:
          200:
            content:
              application/json:
                schema: SingleGcnSummary
          400:
            content:
              application/json:
                schema: Error
        """
        if summary_id is None:
            return self.error("Summary ID is required")

        with self.Session() as session:
            stmt = GcnSummary.select(session.user_or_token, mode="read").where(
                GcnSummary.id == summary_id,
                GcnSummary.dateobs == dateobs,
            )
            summary = session.scalars(stmt).first()
            if summary is None:
                return self.error("Summary not found", status=404)

            # call the deferred text column
            summary.text

            return self.success(data=summary)

    @auth_or_token
    def patch(self, dateobs, summary_id):
        """
        description: Update a GCN summary
        tags:
          - gcn
        parameters:
          - in: path
            name: dateobs
            required: true
            schema:
              type: string
          - in: path
            name: summary_id
            required: true
            schema:
              type: integer
        requestBody:
          content:
            application/json:
              schema:
                type: object
                properties:
                  text:
                    type: string
        responses:
          200:
            content:
              application/json:
                schema: SingleGcnSummary
          400:
            content:
              application/json:
                schema: Error
        """
        data = self.get_json()
        if data is None or data == {}:
            return self.error("No data provided")

        if summary_id is None:
            return self.error("Summary ID is required")

        try:
            summary_id = int(summary_id)
        except ValueError:
            return self.error("Invalid summary_id value.")

        with self.Session() as session:
            stmt = GcnSummary.select(session.user_or_token, mode="update").where(
                GcnSummary.id == summary_id,
                GcnSummary.dateobs == dateobs,
            )
            summary = session.scalars(stmt).first()
            if summary is None:
                return self.error("Summary not found", status=404)

            if data["body"] != {}:
                body_str = data["body"].strip('"')
                summary.text = body_str
            else:
                return self.error("body not found")

            session.commit()

            self.push(
                action="skyportal/REFRESH_GCN_EVENT",
                payload={"gcnEvent_dateobs": dateobs},
            )

            return self.success(data=summary)

    @auth_or_token
    def delete(self, dateobs, summary_id):
        """
        ---
        description: Delete a GCN summary
        tags:
          - gcn
        parameters:
          - in: path
            name: summary_id
            required: true
            schema:
              type: integer
        responses:
          200:
            content:
              application/json:
                schema: Success
          400:
            content:
              application/json:
                schema: Error
        """
        if summary_id is None:
            return self.error("Summary ID is required")

        with self.Session() as session:
            stmt = GcnSummary.select(session.user_or_token, mode="delete").where(
                GcnSummary.id == summary_id,
                GcnSummary.dateobs == dateobs,
            )
            summary = session.scalars(stmt).first()
            if summary is None:
                return self.error("Summary not found", status=404)

            if summary.text.strip().lower() == "pending" and datetime.datetime.now() < (
                summary.created_at + datetime.timedelta(hours=1)
            ):
                return self.error(
                    "Cannot delete a recently created summary (less than 1 hour) that is still pending"
                )

            session.delete(summary)
            session.commit()

            self.push(
                action="skyportal/REFRESH_GCN_EVENT",
                payload={"gcnEvent_dateobs": dateobs},
            )

        return self.success()


def add_gcn_report(
    report_id,
    user_id,
    user_accessible_group_ids,
    dateobs,
    group_id,
    start_date,
    end_date,
    localization_name,
    localization_cumprob=0.90,
    number_of_detections=1,
    show_sources=True,
    show_observations=False,
    show_survey_efficiencies=False,
    photometry_in_window=True,
    stats_method='python',
    instrument_ids=None,
):
    if Session.registry.has():
        session = Session()
    else:
        session = Session(bind=DBSession.session_factory.kw["bind"])

    try:
        user = session.query(User).get(user_id)
        user_accessible_group_ids = [group.id for group in user.accessible_groups]
        session.user_or_token = user

        gcn_report = session.query(GcnReport).get(report_id)

        try:
            group = session.query(Group).get(group_id)
            event = session.query(GcnEvent).filter(GcnEvent.dateobs == dateobs).first()
            localization = (
                session.query(Localization)
                .filter(
                    Localization.dateobs == dateobs,
                    Localization.localization_name == localization_name,
                )
                .first()
            )
            start_date_mjd = Time(arrow.get(start_date).datetime).mjd
            end_date_mjd = Time(arrow.get(end_date).datetime).mjd

            contents = {}
            if show_sources:
                source_page_number = 1
                sources = []
                while True:
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    # get the sources in the event
                    coroutine = get_sources(
                        user_id=user.id,
                        session=session,
                        group_ids=[group.id],
                        user_accessible_group_ids=user_accessible_group_ids,
                        first_detected_date=start_date,
                        last_detected_date=end_date,
                        localization_dateobs=dateobs,
                        localization_name=localization_name,
                        localization_cumprob=localization_cumprob,
                        number_of_detections=number_of_detections,
                        page_number=source_page_number,
                        num_per_page=MAX_SOURCES_PER_PAGE,
                    )
                    sources_data = loop.run_until_complete(coroutine)
                    sources.extend(sources_data['sources'])
                    source_page_number += 1

                    if len(sources_data['sources']) < MAX_SOURCES_PER_PAGE:
                        break
                if len(sources) > 0:
                    obj_ids = [source['id'] for source in sources]
                    sources_with_status = session.scalars(
                        SourcesConfirmedInGCN.select(user).where(
                            SourcesConfirmedInGCN.obj_id.in_(obj_ids),
                            SourcesConfirmedInGCN.dateobs == dateobs,
                        )
                    ).all()
                    for source in sources:
                        source["source_in_gcn"] = next(
                            (
                                source_in_gcn.to_dict()
                                for source_in_gcn in sources_with_status
                                if source_in_gcn.obj_id == source['id']
                            ),
                            None,
                        )

                        stmt = Photometry.select(user).where(
                            Photometry.obj_id == source['id']
                        )
                        if photometry_in_window:
                            stmt = stmt.where(
                                Photometry.mjd >= start_date_mjd,
                                Photometry.mjd <= end_date_mjd,
                            )
                        photometry = session.scalars(stmt).all()
                        if len(photometry) > 0:
                            source["photometry"] = [
                                serialize(phot, 'ab', 'mag') for phot in photometry
                            ]
                        else:
                            source["photometry"] = []

                contents["sources"] = sources

            if show_observations:
                # get the executed obs, by instrument
                observations = []
                observation_statistics = []

                start_date = arrow.get(start_date).datetime
                end_date = arrow.get(end_date).datetime

                if instrument_ids is not None:
                    stmt = Instrument.select(user).where(
                        Instrument.id.in_(instrument_ids)
                    )
                else:
                    stmt = Instrument.select(user).options(
                        joinedload(Instrument.telescope)
                    )
                instruments = session.scalars(stmt).all()
                if instruments is not None:
                    for instrument in instruments:
                        data = get_observations(
                            session,
                            start_date,
                            end_date,
                            telescope_name=instrument.telescope.name,
                            instrument_name=instrument.name,
                            localization_dateobs=dateobs,
                            localization_name=localization_name,
                            localization_cumprob=localization_cumprob,
                            return_statistics=True,
                            includeGeoJSON=True,
                            stats_method=stats_method,
                            n_per_page=MAX_OBSERVATIONS,
                            page_number=1,
                            sort_by="obstime",
                            sort_order="asc",
                        )
                        observation_statistics.append(
                            {
                                'telescope_name': instrument.telescope.name,
                                'instrument_name': instrument.name,
                                'probability': data['probability'],
                                'area': data['area'],
                            }
                        )
                        for o in data["observations"]:
                            idx = data["field_ids"].index(o["instrument_field_id"])
                            if idx is not None:
                                o["field_coordinates"] = data["geojson"][idx][
                                    "features"
                                ][0]["geometry"]["coordinates"]
                            if "field" in o:
                                del o["field"]

                        observations.extend(data["observations"])

                contents["observations"] = observations
                contents["observation_statistics"] = observation_statistics

            if show_survey_efficiencies:
                if instrument_ids is not None:
                    stmt = SurveyEfficiencyForObservations.select(user).where(
                        SurveyEfficiencyForObservations.instrument_id.in_(
                            instrument_ids
                        )
                    )
                else:
                    stmt = SurveyEfficiencyForObservations.select(user)
                survey_efficiency_analyses = session.scalars(stmt).all()

                contents["survey_efficiency_analyses"] = [
                    {
                        **analysis.to_dict(),
                        'number_of_transients': analysis.number_of_transients,
                        'number_in_covered': analysis.number_in_covered,
                        'number_detected': analysis.number_detected,
                        'efficiency': analysis.efficiency,
                    }
                    for analysis in survey_efficiency_analyses
                ]

            tags = event.tags
            aliases = event.aliases
            event_properties = event.properties
            localization_properties = localization.properties

            name = None
            for alias in aliases:
                if alias.startswith("LVC#") or alias.startswith("FERMI#"):
                    name = alias.split("#")[1]
                    break

            contents["event"] = {
                "status": "success",
                "name": name,
                "localization_name": localization_name,
                "cumulative_probability": float(localization_cumprob) * 100,
                "tags": list(set(tags)),
                "aliases": list(set(aliases)),
                "event_properties": event_properties,
                "localization_properties": localization_properties,
            }

            gcn_report.data = to_json(contents)
            session.commit()

            flow = Flow()
            flow.push(
                user_id='*',
                action_type="skyportal/REFRESH_GCNEVENT_REPORTS",
                payload={"gcnEvent_dateobs": event.dateobs},
            )

            notification = UserNotification(
                user=user,
                text=f"GCN report *{gcn_report.report_name}* on *{event.dateobs}* created.",
                notification_type="gcn_report",
                url=f"/gcn_events/{event.dateobs}",
            )
            session.add(notification)
            session.commit()

            log(f"Successfully generated GCN report {gcn_report.id}")
        except Exception as e:
            try:
                session.rollback()
                gcn_report = session.query(GcnReport).get(report_id)
                gcn_report.data = to_json({"status": "error", "message": str(e)})
                session.commit()
            except Exception:
                session.rollback()
                pass
            log(f"Unable to update GCN report: {str(e)}")

    except Exception as e:
        log(f"Unable to create GCN report: {str(e)}")
        raise e
    finally:
        session.close()
        Session.remove()


class GcnReportHandler(BaseHandler):
    @auth_or_token
    async def post(self, dateobs, summary_id=None):
        """
        ---
          description: Post report data of a GCN event.
          tags:
            - gcnreports
          parameters:
            - in: body
              name: report_name
              schema:
                type: string
            - in: body
              name: groupId
              required: true
              schema:
                type: string
              description: id of the group that creates the summary.
            - in: body
              name: startDate
              required: true
              schema:
                type: string
              description: Filter by start date
            - in: body
              name: endDate
              required: true
              schema:
                type: string
              description: Filter by end date
            - in: body
              name: localizationName
              schema:
                type: string
              description: Name of localization / skymap to use.
            - in: body
              name: localizationCumprob
              schema:
                type: number
              description: Cumulative probability up to which to include fields. Defaults to 0.95.
            - in: body
              name: numberDetections
              nullable: true
              schema:
                type: number
              description: Return only sources who have at least numberDetections detections. Defaults to 2.
            - in: body
              name: showSources
              required: true
              schema:
                type: bool
              description: Show sources in the summary
            - in: body
              name: showObservations
              required: true
              schema:
                type: bool
              description: Show observations in the summary
            - in: body
              name: noText
              schema:
                type: bool
              description: Do not include text in the summary, only tables.
            - in: body
              name: photometryInWindow
              schema:
                type: bool
              description: Limit photometry to that within startDate and endDate.
            - in: body
              name: statsMethod
              schema:
                type: string
              description: Method to use for calculating statistics. Defaults to python. Options are python and db.
            - in: body
              name: instrumentIds
              schema:
                type: string
              description: List of instrument ids to include in the summary. Defaults to all instruments if not specified.

          responses:
            200:
              content:
                application/json:
                  schema:
                    allOf:
                      - $ref: '#/components/schemas/Success'
                      - type: object
                        properties:
                          data:
                            type: string
                            description: GCN summary
            400:
              content:
                application/json:
                  schema: Error
        """

        data = self.get_json()
        report_name = data.get("reportName", None)
        group_id = data.get("groupId", None)
        start_date = data.get("startDate", None)
        end_date = data.get("endDate", None)
        localization_name = data.get("localizationName", None)
        localization_cumprob = data.get("localizationCumprob", 0.95)
        number_of_detections = data.get("numberDetections", 2)
        show_sources = data.get("showSources", False)
        show_observations = data.get("showObservations", False)
        show_survey_efficiencies = data.get("showSurveyEfficiencies", False)
        photometry_in_window = data.get("photometryInWindow", False)
        stats_method = data.get("statsMethod", "python")
        instrument_ids = data.get("instrumentIds", None)

        class Validator(Schema):
            start_date = UTCTZnaiveDateTime(required=False, missing=None)
            end_date = UTCTZnaiveDateTime(required=False, missing=None)

        validator_instance = Validator()
        params_to_be_validated = {}
        if start_date is not None:
            params_to_be_validated['start_date'] = start_date
        if end_date is not None:
            params_to_be_validated['end_date'] = end_date

        try:
            validated = validator_instance.load(params_to_be_validated)
        except ValidationError as e:
            return self.error(f'Error parsing query params: {e.args[0]}.')

        start_date = validated['start_date']
        end_date = validated['end_date']

        if report_name is None:
            return self.error("reportName is required")

        if group_id is None:
            return self.error("Group ID is required")

        if stats_method not in ["db", "python"]:
            return self.error(
                "statsMethod for observations querying must be 'db' or 'python'"
            )

        if instrument_ids is not None:
            try:
                instrument_ids = [
                    int(instrument_id) for instrument_id in instrument_ids
                ]
                if len(instrument_ids) == 0:
                    instrument_ids = None
            except ValueError:
                return self.error("Instrument IDs must be a list of integers")

        try:
            number_of_detections = int(number_of_detections)
        except ValueError:
            return self.error("numberDetections must be an integer")

        with self.Session() as session:
            stmt = GcnEvent.select(session.user_or_token).where(
                GcnEvent.dateobs == dateobs
            )
            event = session.scalars(stmt).first()

            if event is None:
                return self.error("Event not found", status=404)

            stmt = Group.select(session.user_or_token).where(Group.id == group_id)
            group = session.scalars(stmt).first()
            if group is None:
                return self.error(f"Group not found with ID {group_id}")

            # verify that the user doesn't already have a summary with this title for this event
            stmt = GcnReport.select(session.user_or_token, mode="read").where(
                GcnReport.dateobs == dateobs,
                GcnReport.report_name == report_name,
                GcnReport.group_id == group_id,
                GcnReport.sent_by_id == self.associated_user_object.id,
            )
            existing_report = session.scalars(stmt).first()
            if existing_report is not None:
                return self.error(
                    "A report with the same name, group, and event already exists for this user"
                )

            gcn_report = GcnReport(
                dateobs=event.dateobs,
                report_name=report_name,
                data={"status": "pending"},
                sent_by_id=self.associated_user_object.id,
                group_id=group_id,
            )
            session.add(gcn_report)
            session.commit()

            report_id = gcn_report.id
            user_id = self.associated_user_object.id
            user_accessible_group_ids = [
                group.id for group in self.associated_user_object.accessible_groups
            ]

            try:
                IOLoop.current().run_in_executor(
                    None,
                    lambda: add_gcn_report(
                        report_id=report_id,
                        user_id=user_id,
                        user_accessible_group_ids=user_accessible_group_ids,
                        dateobs=dateobs,
                        group_id=group_id,
                        start_date=start_date,
                        end_date=end_date,
                        localization_name=localization_name,
                        localization_cumprob=localization_cumprob,
                        number_of_detections=number_of_detections,
                        show_sources=show_sources,
                        show_observations=show_observations,
                        show_survey_efficiencies=show_survey_efficiencies,
                        photometry_in_window=photometry_in_window,
                        stats_method=stats_method,
                        instrument_ids=instrument_ids,
                    ),
                )
                return self.success({"id": summary_id})
            except Exception as e:
                return self.error(f"Error generating report: {e}")

    @auth_or_token
    def get(self, dateobs, report_id=None):
        """
        ---
        description: Retrieve a GCN report
        tags:
          - gcn
        parameters:
          - in: path
            name: dateobs
            required: true
            schema:
              type: string
          - in: path
            name: summary_id
            required: true
            schema:
              type: integer
        responses:
          200:
            content:
              application/json:
                schema: SingleGcnReport
          400:
            content:
              application/json:
                schema: Error
        """
        if report_id is None:
            with self.Session() as session:
                stmt = GcnReport.select(session.user_or_token, mode="read").where(
                    GcnReport.dateobs == dateobs
                )
                reports = session.scalars(stmt).all()
                reports = sorted(
                    (
                        {
                            **p.to_dict(),
                            "sent_by": p.sent_by.to_dict(),
                            "group": p.group.to_dict(),
                        }
                        for p in reports
                    ),
                    key=lambda x: x["created_at"],
                    reverse=True,
                )
                return self.success(data=reports)

        with self.Session() as session:
            stmt = GcnReport.select(session.user_or_token, mode="read").where(
                GcnReport.id == report_id,
                GcnReport.dateobs == dateobs,
            )
            report = session.scalars(stmt).first()
            if report is None:
                return self.error("Report not found", status=404)

            report.data  # get the data column (deferred)
            return self.success(data=report)

    @auth_or_token
    async def patch(self, dateobs, report_id):
        """
        description: Update a GCN report
        tags:
          - gcn
        parameters:
          - in: path
            name: dateobs
            required: true
            schema:
              type: string
          - in: path
            name: report_id
            required: true
            schema:
              type: integer
        requestBody:
          content:
            application/json:
              schema:
                type: object
                properties:
                  data:
                    type: object
        responses:
          200:
            content:
              application/json:
                schema: SingleGcnReport
          400:
            content:
              application/json:
                schema: Error
        """
        data = self.get_json()
        if data is None or data == {}:
            return self.error("No data provided")

        if report_id is None:
            return self.error("Report ID is required")

        with self.Session() as session:
            stmt = GcnReport.select(session.user_or_token, mode="update").where(
                GcnReport.id == report_id,
                GcnReport.dateobs == dateobs,
            )
            report = session.scalars(stmt).first()
            if report is None:
                return self.error("Report not found", status=404)

            report_id = report.id

            if "data" in data:
                if data["data"] != {}:
                    new_data = data["data"]
                    if len(new_data.get('sources', [])) > 0:
                        try:
                            loop = asyncio.get_event_loop()
                        except Exception:
                            loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)

                        old_data = report.data
                        old_data = (
                            json.loads(old_data)
                            if isinstance(old_data, str)
                            else old_data
                        )

                        # if there is any duplicate source, return error
                        if len(new_data.get('sources', [])) != len(
                            {
                                source.get('id', None)
                                for source in new_data.get('sources', [])
                            }
                        ):
                            return self.error(
                                "Duplicate sources in report, please remove duplicates and try again"
                            )
                        for i, source in enumerate(new_data.get('sources', [])):
                            if source not in old_data.get('sources', []):
                                # check if source exists in the database
                                source_id = source.get('id', None)
                                source = await get_source(
                                    source_id,
                                    self.associated_user_object.id,
                                    session,
                                    include_photometry=False,
                                )
                                if source is None:
                                    return self.error(
                                        f"Source {source_id} not found in the database, not updating report"
                                    )

                                stmt = Photometry.select(session.user_or_token).where(
                                    Photometry.obj_id == source['id']
                                )
                                photometry = session.scalars(stmt).all()
                                if len(photometry) > 0:
                                    source["photometry"] = [
                                        serialize(phot, 'ab', 'mag')
                                        for phot in photometry
                                    ]
                                else:
                                    source["photometry"] = []

                                source["source_in_gcn"] = session.scalar(
                                    SourcesConfirmedInGCN.select(
                                        session.user_or_token
                                    ).where(
                                        SourcesConfirmedInGCN.obj_id == source_id,
                                        SourcesConfirmedInGCN.dateobs == dateobs,
                                    )
                                )

                                source["comment"] = new_data['sources'][i].get(
                                    'comment', ""
                                )
                                # add source to report
                                new_data['sources'][i] = source

                    report.data = to_json(new_data)
                else:
                    return self.error("data not found")

            if data.get("published", None) is not None and isinstance(
                data.get("published", None), bool
            ):
                publish = data["published"]
                if publish:
                    report.publish()
                else:
                    report.unpublish()
            else:
                report.generate_report()

            session.commit()

            self.push_all(
                action="skyportal/REFRESH_GCNEVENT_REPORT",
                payload={"report_id": report_id},
            )

            return self.success(data=report)

    @auth_or_token
    def delete(self, dateobs, report_id):
        """
        ---
        description: Delete a GCN report
        tags:
          - gcn
        parameters:
          - in: path
            name: report_id
            required: true
            schema:
              type: integer
        responses:
          200:
            content:
              application/json:
                schema: Success
          400:
            content:
              application/json:
                schema: Error
        """
        if report_id is None:
            return self.error("Report ID is required")

        with self.Session() as session:
            stmt = GcnReport.select(session.user_or_token, mode="delete").where(
                GcnReport.id == report_id,
                GcnReport.dateobs == dateobs,
            )
            report = session.scalars(stmt).first()
            if report is None:
                return self.error("Report not found", status=404)

            data = report.data
            if isinstance(data, str):
                data = json.loads(data)

            if len(data.keys()) == 0 and datetime.datetime.now() < (
                report.created_at + datetime.timedelta(hours=1)
            ):
                return self.error(
                    "Cannot delete a recently created report (less than 1 hour) that is still pending"
                )

            report.unpublish()

            session.delete(report)
            session.commit()

            self.push(
                action="skyportal/REFRESH_GCN_EVENT",
                payload={"gcnEvent_dateobs": dateobs},
            )

        return self.success()


class LocalizationDownloadHandler(BaseHandler):
    @auth_or_token
    async def get(self, dateobs, localization_name):
        """
        ---
        description: Download a GCN localization skymap
        tags:
          - localizations
        parameters:
          - in: path
            name: dateobs
            required: true
            schema:
              type: string
          - in: path
            name: localization_name
            required: true
            schema:
              type: string
        responses:
          200:
            content:
              application/json:
                schema: LocalizationHandlerGet
          400:
            content:
              application/json:
                schema: Error
        """

        dateobs = dateobs.strip()
        try:
            arrow.get(dateobs)
        except arrow.parser.ParserError as e:
            return self.error(f'Failed to parse dateobs: str({e})')

        localization_name = localization_name.strip()
        local_temp_files = []

        with self.Session() as session:
            try:
                localization = session.scalars(
                    Localization.select(session.user_or_token).where(
                        Localization.dateobs == dateobs,
                        Localization.localization_name == localization_name,
                    )
                ).first()
                if localization is None:
                    return self.error("Localization not found", status=404)

                output_format = 'fits'
                with tempfile.NamedTemporaryFile(suffix='.fits') as fitsfile:
                    localization_path = localization.get_localization_path()
                    if localization_path is None:
                        ligo.skymap.io.write_sky_map(
                            fitsfile.name, localization.table, moc=True
                        )
                        with open(fitsfile.name, mode='rb') as g:
                            content = g.read()
                        local_temp_files.append(fitsfile.name)
                    else:
                        with open(localization_path, mode='rb') as g:
                            content = g.read()

                data = io.BytesIO(content)
                filename = f"{localization.localization_name}.{output_format}"

                await self.send_file(data, filename, output_type=output_format)

            except Exception as e:
                return self.error(f'Failed to create skymap for download: str({e})')
            finally:
                # clean up local files
                for f in local_temp_files:
                    try:
                        os.remove(f)
                    except:  # noqa E722
                        pass


class LocalizationCrossmatchHandler(BaseHandler):
    @auth_or_token
    async def get(self):
        """
        ---
        description: A fits file corresponding to the intersection of the input fits files.
        tags:
          - localizations
        parameters:
          - in: path
            name: dateobs
            required: true
            schema:
              type: dateobs
          - in: path
            name: localization_name
            required: true
            schema:
              type: localization_name
        responses:
          200:
            content:
              application/fits:
                schema:
                  type: string
                  format: binary
          400:
            content:
              application/json:
                schema: Error
        """
        id1 = self.get_query_argument("id1", None)
        id2 = self.get_query_argument("id2", None)
        if id1 is None or id2 is None:
            return self.error("Please provide two localization id")

        id1 = id1.strip()
        id2 = id2.strip()
        local_temp_files = []

        with self.Session() as session:
            try:
                localization1 = session.scalars(
                    Localization.select(session.user_or_token).where(
                        Localization.id == id1,
                    )
                ).first()
                localization2 = session.scalars(
                    Localization.select(session.user_or_token).where(
                        Localization.id == id2,
                    )
                ).first()

                if localization1 is None or localization2 is None:
                    return self.error("Localization not found", status=404)

                output_format = 'fits'

                skymap1 = localization1.flat_2d
                skymap2 = localization2.flat_2d
                skymap = skymap1 * skymap2
                skymap = skymap / np.sum(skymap)

                skymap = hp.reorder(skymap, 'RING', 'NESTED')
                skymap = ligo_bayestar.derasterize(Table([skymap], names=['PROB']))
                with tempfile.NamedTemporaryFile(suffix='.fits') as fitsfile:
                    ligo.skymap.io.write_sky_map(
                        fitsfile.name, skymap, format='fits', moc=True
                    )

                    with open(fitsfile.name, mode='rb') as g:
                        content = g.read()
                    local_temp_files.append(fitsfile.name)

                data = io.BytesIO(content)
                filename = f"{localization1.localization_name}_{localization2.localization_name}.{output_format}"

                await self.send_file(
                    data,
                    filename,
                    output_type=output_format,
                )

            except Exception as e:
                return self.error(f'Failed to create skymap for download: str({e})')
            finally:
                # clean up local files
                for f in local_temp_files:
                    try:
                        os.remove(f)
                    except:  # noqa E722
                        pass


class GcnEventInstrumentFieldHandler(BaseHandler):
    @auth_or_token
    async def get(self, dateobs, instrument_id):
        """
        ---
        description: Compute instrument field probabilities for a skymap
        tags:
          - localizations
          - instruments
        parameters:
          - in: path
            name: dateobs
            required: true
            schema:
              type: string
          - in: path
            name: Instrument ID
            required: true
            schema:
              type: integer
          - in: query
            name: localization_name
            required: true
            schema:
              type: string
            description: Localization map name
          - in: query
            name: integrated_probability
            nullable: true
            schema:
              type: float
            description: Cumulative integrated probability threshold
        responses:
          200:
            content:
              application/json:
                schema: Success
          400:
            content:
              application/json:
                schema: Error
        """

        dateobs = dateobs.strip()
        try:
            arrow.get(dateobs)
        except arrow.parser.ParserError as e:
            return self.error(f'Failed to parse dateobs: str({e})')

        localization_name = self.get_query_argument("localization_name", None)
        integrated_probability = self.get_query_argument("integrated_probability", 0.95)

        with self.Session() as session:
            stmt = Localization.select(session.user_or_token).where(
                Localization.dateobs == dateobs
            )
            if localization_name is not None:
                stmt = stmt.where(Localization.localization_name == localization_name)
            localization = session.scalars(stmt).first()
            if localization is None:
                return self.error("Localization not found", status=404)

            stmt = Instrument.select(session.user_or_token).where(
                Instrument.id == int(instrument_id)
            )
            instrument = session.scalars(stmt).first()
            if instrument is None:
                return self.error(f'No instrument with ID: {instrument_id}')

            cum_prob = (
                sa.func.sum(
                    LocalizationTile.probdensity * LocalizationTile.healpix.area
                )
                .over(order_by=LocalizationTile.probdensity.desc())
                .label('cum_prob')
            )
            localizationtile_subquery = (
                sa.select(LocalizationTile.probdensity, cum_prob).filter(
                    LocalizationTile.localization_id == localization.id
                )
            ).subquery()

            min_probdensity = (
                sa.select(
                    sa.func.min(localizationtile_subquery.columns.probdensity)
                ).filter(
                    localizationtile_subquery.columns.cum_prob <= integrated_probability
                )
            ).scalar_subquery()

            area = (InstrumentFieldTile.healpix * LocalizationTile.healpix).area
            prob = sa.func.sum(LocalizationTile.probdensity * area)

            field_tiles_query = (
                sa.select(InstrumentField.field_id, prob)
                .where(
                    LocalizationTile.localization_id == localization.id,
                    LocalizationTile.probdensity >= min_probdensity,
                    InstrumentFieldTile.instrument_id == instrument.id,
                    InstrumentFieldTile.instrument_field_id == InstrumentField.id,
                    InstrumentFieldTile.healpix.overlaps(LocalizationTile.healpix),
                )
                .group_by(InstrumentField.field_id)
            )

            field_ids, probs = zip(*session.execute(field_tiles_query).all())

            data_out = {'field_ids': field_ids, 'probabilities': probs}
            return self.success(data=data_out)


class GcnEventTriggerHandler(BaseHandler):
    @permissions(['Manage allocations'])
    def get(self, dateobs, allocation_id=None):
        dateobs = dateobs.strip()
        try:
            arrow.get(dateobs)
        except arrow.parser.ParserError as e:
            return self.error(f'Failed to parse dateobs: str({e})')

        with self.Session() as session:
            if allocation_id is not None:
                try:
                    allocation_id = int(allocation_id)
                except ValueError as e:
                    return self.error(f'Failed to parse allocation_id: str({e})')
                try:
                    gcn_triggered = session.scalars(
                        GcnTrigger.select(session.user_or_token).where(
                            GcnTrigger.dateobs == dateobs,
                            GcnTrigger.allocation_id == allocation_id,
                        )
                    ).all()
                    return self.success(data=gcn_triggered)
                except Exception as e:
                    return self.error(
                        f'Failed to get gcn_event triggered status: str({e})'
                    )

            else:
                try:
                    gcn_triggered = session.scalars(
                        GcnTrigger.select(session.user_or_token).where(
                            GcnTrigger.dateobs == dateobs
                        )
                    ).all()
                    return self.success(data=gcn_triggered)
                except Exception as e:
                    return self.error(
                        f'Failed to get gcn_event triggered status: str({e})'
                    )

    @permissions(['Manage allocations'])
    def put(self, dateobs, allocation_id):
        dateobs = dateobs.strip()
        try:
            arrow.get(dateobs)
        except arrow.parser.ParserError as e:
            return self.error(f'Failed to parse dateobs: str({e})')

        data = self.get_json()

        triggered = data.get('triggered', None)
        if triggered is None:
            return self.error("Must specify triggered status")
        elif triggered in ['True', 'true', 't', 'T', True, 'triggered']:
            triggered = True
        elif triggered in ['False', 'false', 'f', 'F', False, 'passed']:
            triggered = False
        else:
            return self.error("Invalid triggered status")

        try:
            allocation_id = int(allocation_id)
        except ValueError:
            return self.error(f'Failed to parse allocation_id: {allocation_id}')

        with self.Session() as session:
            try:
                gcn_triggered = session.scalars(
                    GcnTrigger.select(session.user_or_token).where(
                        GcnTrigger.dateobs == dateobs,
                        GcnTrigger.allocation_id == allocation_id,
                    )
                ).first()
                if gcn_triggered is None:
                    # verify that the event and allocation exist
                    event = session.scalars(
                        GcnEvent.select(session.user_or_token).where(
                            GcnEvent.dateobs == dateobs
                        )
                    ).first()

                    if event is None:
                        return self.error(f'No event with dateobs: {dateobs}')
                    allocation = session.scalars(
                        Allocation.select(session.user_or_token).where(
                            Allocation.id == allocation_id
                        )
                    ).first()
                    if allocation is None:
                        return self.error(f'No allocation with ID: {allocation_id}')

                    gcn_triggered = GcnTrigger(
                        dateobs=dateobs,
                        allocation_id=allocation_id,
                        triggered=triggered,
                    )
                    session.add(gcn_triggered)
                else:
                    gcn_triggered.triggered = triggered
                session.commit()
                self.push_all(
                    "skyportal/REFRESH_GCN_TRIGGERED",
                    payload={"gcnEvent_dateobs": dateobs},
                )
                return self.success(data=gcn_triggered)
            except Exception as e:
                return self.error(f'Failed to set triggered status: str({e})')

    @permissions(['Manage allocations'])
    def delete(self, dateobs, allocation_id):
        dateobs = dateobs.strip()
        try:
            arrow.get(dateobs)
        except arrow.parser.ParserError as e:
            return self.error(f'Failed to parse dateobs: str({e})')

        try:
            allocation_id = int(allocation_id)
        except ValueError:
            return self.error(f'Failed to parse allocation_id: {allocation_id}')

        with self.Session() as session:
            try:
                gcn_triggered = (
                    session.query(GcnTrigger)
                    .filter(
                        GcnTrigger.dateobs == dateobs,
                        GcnTrigger.allocation_id == allocation_id,
                    )
                    .first()
                )
                if gcn_triggered is not None:
                    session.delete(gcn_triggered)
                    session.commit()
                    self.push_all(
                        "skyportal/REFRESH_GCN_TRIGGERED",
                        payload={"gcnEvent_dateobs": dateobs},
                    )
                    return self.success(data=gcn_triggered)
                else:
                    return self.error(
                        f'No gcn triggered status for dateobs={dateobs} and allocation_id={allocation_id}'
                    )
            except Exception as e:
                return self.error(f'Failed to delete triggered status: str({e})')


class ObjGcnEventHandler(BaseHandler):
    @auth_or_token
    def post(self, obj_id):
        """
        ---
        description: Retrieve an object's in-out critera for GcnEvents
        tags:
          - objs
        parameters:
          - in: path
            name: obj_id
            required: true
            schema:
              type: string
        requestBody:
          content:
            application/json:
              schema:
                type: object
                properties:
                  startDate:
                    type: string
                    required: true
                    description: |
                      Arrow-parseable date string (e.g. 2020-01-01).
                      If provided, filter by GcnEvent.dateobs >= startDate.
                  endDate:
                    type: string
                    required: true
                    description: |
                      Arrow-parseable date string (e.g. 2020-01-01).
                      If provided, filter by GcnEvent.dateobs <= startDate.
        responses:
          200:
            content:
              application/json:
                schema: Success
          400:
            content:
              application/json:
                schema: Error
        """

        data = self.get_json()
        start_date = data.get('startDate', None)
        end_date = data.get('endDate', None)
        integrated_probability = data.get('probability', None)

        if start_date is None or end_date is None:
            return self.error("Must provide startDate and endDate query arguments.")

        try:
            start_date = arrow.get(start_date.strip()).datetime
        except Exception as e:
            return self.error(f'Failed to parse startDate: str({e})')

        try:
            end_date = arrow.get(end_date.strip()).datetime
        except Exception as e:
            return self.error(f'Failed to parse endDate: str({e})')

        if (end_date - start_date).days > 31:
            return self.error(
                "startDate and endDate must be within 31 days of each other."
            )

        with self.Session() as session:
            obj = session.scalars(
                Obj.select(session.user_or_token, mode='update').where(Obj.id == obj_id)
            ).first()
            if obj is None:
                return self.error(f"Cannot find object with ID {obj_id}.")

            query = GcnEvent.select(
                session.user_or_token,
            ).where(
                GcnEvent.dateobs >= start_date,
                GcnEvent.dateobs <= end_date,
            )

            event_ids = [event.id for event in session.scalars(query).unique().all()]
            if len(event_ids) == 0:
                return self.error("Cannot find GcnEvents in those bounds.")

            try:
                loop = asyncio.get_event_loop()
            except Exception:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            IOLoop.current().run_in_executor(
                None,
                lambda: crossmatch_gcn_objects(
                    obj_id,
                    event_ids,
                    self.associated_user_object.id,
                    integrated_probability=integrated_probability,
                ),
            )

            return self.success()


def crossmatch_gcn_objects(obj_id, event_ids, user_id, integrated_probability=0.95):
    """Find events in which an object is within the integrated probability contour.
    obj_id : str
        Object ID
    events_id : List[int]
        GCN Event IDs to crossmatch against
    user_id : int
        SkyPortal ID of User posting the crossmatch results
    integrated_probability : float
        Confidence level up to which to perform crossmatch
    """

    if Session.registry.has():
        session = Session()
    else:
        session = Session(bind=DBSession.session_factory.kw["bind"])

    user = session.scalar(sa.select(User).where(User.id == user_id))

    try:
        obj = session.scalars(
            Obj.select(user, mode='update').where(Obj.id == obj_id)
        ).first()
        if obj is None:
            raise ValueError(f"Cannot find object with ID {obj_id}.")

        events = []
        for event_id in event_ids:
            event = session.scalars(
                GcnEvent.select(
                    user,
                    options=[
                        joinedload(GcnEvent.localizations),
                    ],
                ).where(GcnEvent.id == event_id)
            ).first()
            if event is None:
                continue
            if len(event.localizations) == 0:
                continue
            localization_id = event.localizations[0].id

            partition_key = event.dateobs
            # now get the dateobs in the format YYYY_MM
            localizationtile_partition_name = (
                f'{partition_key.year}_{partition_key.month:02d}'
            )
            localizationtilescls = LocalizationTile.partitions.get(
                localizationtile_partition_name, None
            )
            if localizationtilescls is None:
                localizationtilescls = LocalizationTile
            else:
                # check that there is actually a localizationTile with the given localization_id in the partition
                # if not, use the default partition
                if not (
                    session.scalars(
                        sa.select(localizationtilescls.localization_id).where(
                            localizationtilescls.localization_id == localization_id
                        )
                    ).first()
                ):
                    localizationtilescls = LocalizationTile.partitions.get(
                        'def', LocalizationTile
                    )

            cum_prob = (
                sa.func.sum(
                    localizationtilescls.probdensity * localizationtilescls.healpix.area
                )
                .over(order_by=localizationtilescls.probdensity.desc())
                .label('cum_prob')
            )
            localizationtile_subquery = (
                sa.select(localizationtilescls.probdensity, cum_prob).filter(
                    localizationtilescls.localization_id == localization_id
                )
            ).subquery()

            min_probdensity = (
                sa.select(
                    sa.func.min(localizationtile_subquery.columns.probdensity)
                ).filter(
                    localizationtile_subquery.columns.cum_prob <= integrated_probability
                )
            ).scalar_subquery()

            obj_query = sa.select(Obj.id).where(
                Obj.id == obj.id,
                localizationtilescls.localization_id == localization_id,
                localizationtilescls.probdensity >= min_probdensity,
                localizationtilescls.healpix.contains(Obj.healpix),
            )
            obj_check = session.scalars(obj_query).first()
            if obj_check is not None:
                events.append(event.dateobs)

        obj.gcn_crossmatch = events
        session.commit()

        flow = Flow()
        flow.push(
            '*',
            'skyportal/REFRESH_SOURCE',
            payload={'obj_key': obj.internal_key},
        )

        log(f"Generated GCN crossmatch for {obj_id}")
    except Exception as e:
        log(f"Unable to generate GCN crossmatch for {obj_id}: {e}")
    finally:
        session.close()
        Session.remove()


class DefaultGcnTagHandler(BaseHandler):
    @permissions(['Manage GCNs'])
    def post(self):
        """
        ---
        description: Create default gcn tag.
        tags:
          - defaultgcntags
        requestBody:
          content:
            application/json:
              schema: DefaultGcnTagPost
        responses:
          200:
            content:
              application/json:
                schema:
                  allOf:
                    - $ref: '#/components/schemas/Success'
                    - type: object
                      properties:
                        data:
                          type: object
                          properties:
                            id:
                              type: integer
                              description: New default gcn tag ID
        """
        data = self.get_json()

        with self.Session() as session:
            if "default_tag_name" not in data:
                return self.error('Missing default_tag_name')
            else:
                stmt = DefaultGcnTag.select(session.user_or_token).where(
                    DefaultGcnTag.default_tag_name == data['default_tag_name']
                )
                existing_default_tag = session.scalars(stmt).first()
                if existing_default_tag is not None:
                    return self.error(
                        f"A default tag called {data['default_tag_name']} already exists. That name must be unique."
                    )

            if 'filters' in data:
                if not isinstance(data['filters'], dict):
                    return self.error('filters must be a dictionary')
                if not set(list(data['filters'].keys())).issubset(
                    {'gcn_tags', 'notice_types', 'localization_tags'}
                ):
                    return self.error(
                        'filters must be a dictionary with keys in ["gcn_tags", "notice_types", "localization_tags"]'
                    )
                for key in data['filters']:
                    if not isinstance(data['filters'][key], list):
                        return self.error(f'filters[{key}] must be a list')
                    if not all(isinstance(item, str) for item in data['filters'][key]):
                        return self.error(f'filters[{key}] must be a list of strings')

            default_gcn_tag = DefaultGcnTag.__schema__().load(data)

            session.add(default_gcn_tag)
            session.commit()

            self.push_all(action="skyportal/REFRESH_DEFAULT_GCN_TAGS")
            return self.success(data={"id": default_gcn_tag.id})

    @auth_or_token
    def get(self, default_gcn_tag_id=None):
        """
        ---
        single:
          description: Retrieve a single default gcn tag
          tags:
            - defaultgcntags
          parameters:
            - in: path
              name: default_gcn_tag_id
              required: true
              schema:
                type: integer
          responses:
            200:
              content:
                application/json:
                  schema: SingleDefaultGcnTag
            400:
              content:
                application/json:
                  schema: Error
        multiple:
          description: Retrieve all default gcn tags
          tags:
            - filters
          responses:
            200:
              content:
                application/json:
                  schema: ArrayOfDefaultGcnTags
            400:
              content:
                application/json:
                  schema: Error
        """

        with self.Session() as session:
            if default_gcn_tag_id is not None:
                default_gcn_tag = session.scalars(
                    DefaultGcnTag.select(
                        session.user_or_token,
                    ).where(DefaultGcnTag.id == default_gcn_tag_id)
                ).first()
                if default_gcn_tag is None:
                    return self.error(
                        f'Cannot find DefaultGcnTag with ID {default_gcn_tag_id}'
                    )
                return self.success(data=default_gcn_tag)

            default_gcn_tags = (
                session.scalars(
                    DefaultGcnTag.select(
                        session.user_or_token,
                    )
                )
                .unique()
                .all()
            )

            return self.success(data=default_gcn_tags)

    @permissions(['Manage GCNs'])
    def delete(self, default_gcn_tag_id):
        """
        ---
        description: Delete a default gcn tag
        tags:
          - defaultgcntags
        parameters:
          - in: path
            name: default_gcn_tag_id
            required: true
            schema:
              type: integer
        responses:
          200:
            content:
              application/json:
                schema: Success
        """

        with self.Session() as session:
            stmt = DefaultGcnTag.select(session.user_or_token).where(
                DefaultGcnTag.id == default_gcn_tag_id
            )
            default_gcn_tag = session.scalars(stmt).first()

            if default_gcn_tag is None:
                return self.error(
                    'Default observation plan with ID {default_observation_plan_id} is not available.'
                )

            session.delete(default_gcn_tag)
            session.commit()
            self.push_all(action="skyportal/REFRESH_DEFAULT_GCN_TAGS")
            return self.success()
